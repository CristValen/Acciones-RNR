{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgs/BHtHzpW6B6zJZG7wxz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristValen/Acciones-RNR/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMJj8KFSW8rb",
        "outputId": "0f543dcc-75af-439d-96e0-3af5b64bbdc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b424dc865398>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Obtén las predicciones de probabilidad para cada clase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Calcula las métricas para cada clase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Establecer la semilla para hacer el código reproducible\n",
        "np.random.seed(42)\n",
        "\n",
        "# Codificación de las etiquetas\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Esto convierte las clases 'promotor', 'neutro' y 'detractor' en 0, 1 y 2 respectivamente\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear una red neuronal densa con Keras para 'promotor' vs 'no promotor'\n",
        "modelo_promotor = Sequential()\n",
        "modelo_promotor.add(Dense(12, input_dim=X_train_res.shape[1], activation='relu'))\n",
        "modelo_promotor.add(Dense(8, activation='relu'))\n",
        "modelo_promotor.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo_promotor.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "y_binary_promotor = (y_train_res == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "modelo_promotor.fit(X_train_res, y_binary_promotor, epochs=150, batch_size=10)\n",
        "\n",
        "# Crear una red neuronal densa con Keras para 'detractor' vs 'no detractor'\n",
        "modelo_detractor = Sequential()\n",
        "modelo_detractor.add(Dense(12, input_dim=X_train_res.shape[1], activation='relu'))\n",
        "modelo_detractor.add(Dense(8, activation='relu'))\n",
        "modelo_detractor.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo_detractor.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "y_binary_detractor = (y_train_res == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "modelo_detractor.fit(X_train_res, y_binary_detractor, epochs=150, batch_size=10)\n",
        "\n",
        "# Función para calcular el valor KS\n",
        "def calc_ks(data):\n",
        "    data['good'] = (data['label'] == 0).astype(int)\n",
        "    data['bad'] = (data['label'] == 1).astype(int)\n",
        "    data['bucket'] = (data['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped = data.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob'] = grouped.max().probability\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable = kstable.reset_index()\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = np.round(((kstable.bads / data.bad.sum()).cumsum() - (kstable.goods / data.good.sum()).cumsum()), 4) * 100\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Función para calcular el coeficiente Gini\n",
        "def calc_gini(y_verdadero, y_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_verdadero, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc - 1\n",
        "    return gini\n",
        "\n",
        "# Función para calcular las métricas de rendimiento\n",
        "def calcular_metricas(y_verdadero, y_pred, probas):\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(classification_report(y_verdadero, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_verdadero, y_pred)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[i for i in np.unique(y_verdadero)],\n",
        "                         columns=[i for i in np.unique(y_verdadero)])\n",
        "    print(\"Matriz de confusión:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    print(\"Precisión del modelo:\")\n",
        "    print(accuracy_score(y_verdadero, y_pred))\n",
        "\n",
        "    print(\"Puntuación AUC-ROC:\")\n",
        "    print(roc_auc_score(y_verdadero, probas))\n",
        "\n",
        "    data = pd.DataFrame({'label': y_verdadero, 'probability': probas})\n",
        "    ks = calc_ks(data)\n",
        "    print(\"KS:\")\n",
        "    print(ks)\n",
        "\n",
        "    gini = calc_gini(y_verdadero, probas)\n",
        "    print(f\"Gini: {gini}\")\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de validación\n",
        "probas_val_promotor = modelo_promotor.predict_proba(X_val)[:, 1]\n",
        "probas_val_detractor = modelo_detractor.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de validación\n",
        "print(\"Métricas de rendimiento en el conjunto de validación:\")\n",
        "print(\"\\nPromotor vs No Promotor:\")\n",
        "calcular_metricas(y_val == 0, (probas_val_promotor > 0.5).astype(int), probas_val_promotor)\n",
        "print(\"\\nDetractor vs No Detractor:\")\n",
        "calcular_metricas(y_val == 2, (probas_val_detractor > 0.5).astype(int), probas_val_detractor)\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de prueba\n",
        "probas_test_promotor = modelo_promotor.predict_proba(X_test)[:, 1]\n",
        "probas_test_detractor = modelo_detractor.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de prueba\n",
        "print(\"Métricas de rendimiento en el conjunto de prueba:\")\n",
        "print(\"\\nPromotor vs No Promotor:\")\n",
        "calcular_metricas(y_test == 0, (probas_test_promotor > 0.5).astype(int), probas_test_promotor)\n",
        "print(\"\\nDetractor vs No Detractor:\")\n",
        "calcular_metricas(y_test == 2, (probas_test_detractor > 0.5).astype(int), probas_test_detractor)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la importancia de las variables por permutación\n",
        "result = permutation_importance(modelo_promotor, X_val, y_val, n_repeats=10, random_state=42, scoring=custom_score)\n",
        "\n",
        "# Obtener la importancia de las variables\n",
        "importancia_promotor = pd.DataFrame({\n",
        "    'variable': X.columns,\n",
        "    'importancia': result.importances_mean\n",
        "})\n",
        "\n",
        "# Calcular la importancia en porcentajes\n",
        "importancia_promotor['importancia_porcentaje'] = 100 * (importancia_promotor['importancia'] / importancia_promotor['importancia'].sum())\n",
        "\n",
        "# Ordenar las variables de mayor a menor importancia\n",
        "importancia_promotor = importancia_promotor.sort_values('importancia_porcentaje', ascending=False)\n",
        "\n",
        "# Asegurarse de que se muestren todas las filas\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "print(\"Importancia de las variables para el modelo 'promotor' (en porcentajes):\")\n",
        "print(importancia_promotor)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-MPQoFtKxyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Establecer la semilla para hacer el código reproducible\n",
        "np.random.seed(42)\n",
        "\n",
        "# Codificación de las etiquetas\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Esto convierte las clases 'promotor', 'neutro' y 'detractor' en 0, 1 y 2 respectivamente\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear un modelo LGBMClassifier para 'promotor' vs 'no promotor'\n",
        "y_binary_promotor = (y_train_res == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "modelo_promotor = LGBMClassifier(n_estimators=150, random_state=42)\n",
        "modelo_promotor.fit(X_train_res, y_binary_promotor)\n",
        "\n",
        "# Crear un modelo LGBMClassifier para 'detractor' vs 'no detractor'\n",
        "y_binary_detractor = (y_train_res == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "modelo_detractor = LGBMClassifier(n_estimators=150, random_state=42)\n",
        "modelo_detractor.fit(X_train_res, y_binary_detractor)\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de validación\n",
        "probas_val_promotor = modelo_promotor.predict_proba(X_val)[:, 1]\n",
        "probas_val_detractor = modelo_detractor.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Función para calcular el valor KS\n",
        "def calc_ks(data):\n",
        "    data['good'] = (data['label'] == 0).astype(int)\n",
        "    data['bad'] = (data['label'] == 1).astype(int)\n",
        "    data['bucket'] = (data['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped = data.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob'] = grouped.max().probability\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable = kstable.reset_index()\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = np.round(((kstable.bads / data.bad.sum()).cumsum() - (kstable.goods / data.good.sum()).cumsum()), 4) * 100\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Función para calcular el coeficiente Gini\n",
        "def calc_gini(y_verdadero, y_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_verdadero, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc - 1\n",
        "    return gini\n",
        "\n",
        "# Función para calcular las métricas de rendimiento\n",
        "def calcular_metricas(y_verdadero, y_pred, probas):\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(classification_report(y_verdadero, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_verdadero, y_pred)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[i for i in np.unique(y_verdadero)],\n",
        "                         columns=[i for i in np.unique(y_verdadero)])\n",
        "    print(\"Matriz de confusión:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    print(\"Precisión del modelo:\")\n",
        "    print(accuracy_score(y_verdadero, y_pred))\n",
        "\n",
        "    print(\"Puntuación AUC-ROC:\")\n",
        "    print(roc_auc_score(y_verdadero, probas))\n",
        "\n",
        "    data = pd.DataFrame({'label': y_verdadero, 'probability': probas})\n",
        "    ks = calc_ks(data)\n",
        "    print(\"KS:\")\n",
        "    print(ks)\n",
        "\n",
        "    gini = calc_gini(y_verdadero, probas)\n",
        "    print(f\"Gini: {gini}\")\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de validación\n",
        "y_val_promotor = (y_val == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_val_detractor = (y_val == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"Métricas para el modelo 'promotor':\")\n",
        "calcular_metricas(y_val_promotor, modelo_promotor.predict(X_val), probas_val_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor':\")\n",
        "calcular_metricas(y_val_detractor, modelo_detractor.predict(X_val), probas_val_detractor)\n"
      ],
      "metadata": {
        "id": "vdNKrq4ETZ8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}