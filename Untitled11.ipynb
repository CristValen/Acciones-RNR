{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2UnTSmn0idB42vrEqKwWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristValen/Acciones-RNR/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMJj8KFSW8rb",
        "outputId": "0f543dcc-75af-439d-96e0-3af5b64bbdc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b424dc865398>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Obtén las predicciones de probabilidad para cada clase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Calcula las métricas para cada clase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Establecer la semilla para hacer el código reproducible\n",
        "np.random.seed(42)\n",
        "\n",
        "# Codificación de las etiquetas\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Esto convierte las clases 'promotor', 'neutro' y 'detractor' en 0, 1 y 2 respectivamente\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear una red neuronal densa con Keras para 'promotor' vs 'no promotor'\n",
        "modelo_promotor = Sequential()\n",
        "modelo_promotor.add(Dense(12, input_dim=X_train_res.shape[1], activation='relu'))\n",
        "modelo_promotor.add(Dense(8, activation='relu'))\n",
        "modelo_promotor.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo_promotor.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "y_binary_promotor = (y_train_res == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "modelo_promotor.fit(X_train_res, y_binary_promotor, epochs=150, batch_size=10)\n",
        "\n",
        "# Crear una red neuronal densa con Keras para 'detractor' vs 'no detractor'\n",
        "modelo_detractor = Sequential()\n",
        "modelo_detractor.add(Dense(12, input_dim=X_train_res.shape[1], activation='relu'))\n",
        "modelo_detractor.add(Dense(8, activation='relu'))\n",
        "modelo_detractor.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo_detractor.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "y_binary_detractor = (y_train_res == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "modelo_detractor.fit(X_train_res, y_binary_detractor, epochs=150, batch_size=10)\n",
        "\n",
        "# Función para calcular el valor KS\n",
        "def calc_ks(data):\n",
        "    data['good'] = (data['label'] == 0).astype(int)\n",
        "    data['bad'] = (data['label'] == 1).astype(int)\n",
        "    data['bucket'] = (data['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped = data.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob'] = grouped.max().probability\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable = kstable.reset_index()\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = np.round(((kstable.bads / data.bad.sum()).cumsum() - (kstable.goods / data.good.sum()).cumsum()), 4) * 100\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Función para calcular el coeficiente Gini\n",
        "def calc_gini(y_verdadero, y_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_verdadero, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc - 1\n",
        "    return gini\n",
        "\n",
        "# Función para calcular las métricas de rendimiento\n",
        "def calcular_metricas(y_verdadero, y_pred, probas):\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(classification_report(y_verdadero, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_verdadero, y_pred)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[i for i in np.unique(y_verdadero)],\n",
        "                         columns=[i for i in np.unique(y_verdadero)])\n",
        "    print(\"Matriz de confusión:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    print(\"Precisión del modelo:\")\n",
        "    print(accuracy_score(y_verdadero, y_pred))\n",
        "\n",
        "    print(\"Puntuación AUC-ROC:\")\n",
        "    print(roc_auc_score(y_verdadero, probas))\n",
        "\n",
        "    data = pd.DataFrame({'label': y_verdadero, 'probability': probas})\n",
        "    ks = calc_ks(data)\n",
        "    print(\"KS:\")\n",
        "    print(ks)\n",
        "\n",
        "    gini = calc_gini(y_verdadero, probas)\n",
        "    print(f\"Gini: {gini}\")\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de validación\n",
        "probas_val_promotor = modelo_promotor.predict_proba(X_val)[:, 1]\n",
        "probas_val_detractor = modelo_detractor.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de validación\n",
        "print(\"Métricas de rendimiento en el conjunto de validación:\")\n",
        "print(\"\\nPromotor vs No Promotor:\")\n",
        "calcular_metricas(y_val == 0, (probas_val_promotor > 0.5).astype(int), probas_val_promotor)\n",
        "print(\"\\nDetractor vs No Detractor:\")\n",
        "calcular_metricas(y_val == 2, (probas_val_detractor > 0.5).astype(int), probas_val_detractor)\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de prueba\n",
        "probas_test_promotor = modelo_promotor.predict_proba(X_test)[:, 1]\n",
        "probas_test_detractor = modelo_detractor.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de prueba\n",
        "print(\"Métricas de rendimiento en el conjunto de prueba:\")\n",
        "print(\"\\nPromotor vs No Promotor:\")\n",
        "calcular_metricas(y_test == 0, (probas_test_promotor > 0.5).astype(int), probas_test_promotor)\n",
        "print(\"\\nDetractor vs No Detractor:\")\n",
        "calcular_metricas(y_test == 2, (probas_test_detractor > 0.5).astype(int), probas_test_detractor)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la importancia de las variables por permutación\n",
        "result = permutation_importance(modelo_promotor, X_val, y_val, n_repeats=10, random_state=42, scoring=custom_score)\n",
        "\n",
        "# Obtener la importancia de las variables\n",
        "importancia_promotor = pd.DataFrame({\n",
        "    'variable': X.columns,\n",
        "    'importancia': result.importances_mean\n",
        "})\n",
        "\n",
        "# Calcular la importancia en porcentajes\n",
        "importancia_promotor['importancia_porcentaje'] = 100 * (importancia_promotor['importancia'] / importancia_promotor['importancia'].sum())\n",
        "\n",
        "# Ordenar las variables de mayor a menor importancia\n",
        "importancia_promotor = importancia_promotor.sort_values('importancia_porcentaje', ascending=False)\n",
        "\n",
        "# Asegurarse de que se muestren todas las filas\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "print(\"Importancia de las variables para el modelo 'promotor' (en porcentajes):\")\n",
        "print(importancia_promotor)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-MPQoFtKxyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Establecer la semilla para hacer el código reproducible\n",
        "np.random.seed(42)\n",
        "\n",
        "# Codificación de las etiquetas\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Esto convierte las clases 'promotor', 'neutro' y 'detractor' en 0, 1 y 2 respectivamente\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear un modelo LGBMClassifier para 'promotor' vs 'no promotor'\n",
        "y_binary_promotor = (y_train_res == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "modelo_promotor = LGBMClassifier(n_estimators=150, random_state=42)\n",
        "modelo_promotor.fit(X_train_res, y_binary_promotor)\n",
        "\n",
        "# Crear un modelo LGBMClassifier para 'detractor' vs 'no detractor'\n",
        "y_binary_detractor = (y_train_res == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "modelo_detractor = LGBMClassifier(n_estimators=150, random_state=42)\n",
        "modelo_detractor.fit(X_train_res, y_binary_detractor)\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de validación\n",
        "probas_val_promotor = modelo_promotor.predict_proba(X_val)[:, 1]\n",
        "probas_val_detractor = modelo_detractor.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Función para calcular el valor KS\n",
        "def calc_ks(data):\n",
        "    data['good'] = (data['label'] == 0).astype(int)\n",
        "    data['bad'] = (data['label'] == 1).astype(int)\n",
        "    data['bucket'] = (data['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped = data.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob'] = grouped.max().probability\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable = kstable.reset_index()\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = np.round(((kstable.bads / data.bad.sum()).cumsum() - (kstable.goods / data.good.sum()).cumsum()), 4) * 100\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Función para calcular el coeficiente Gini\n",
        "def calc_gini(y_verdadero, y_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_verdadero, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc - 1\n",
        "    return gini\n",
        "\n",
        "# Función para calcular las métricas de rendimiento\n",
        "def calcular_metricas(y_verdadero, y_pred, probas):\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(classification_report(y_verdadero, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_verdadero, y_pred)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[i for i in np.unique(y_verdadero)],\n",
        "                         columns=[i for i in np.unique(y_verdadero)])\n",
        "    print(\"Matriz de confusión:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    print(\"Precisión del modelo:\")\n",
        "    print(accuracy_score(y_verdadero, y_pred))\n",
        "\n",
        "    print(\"Puntuación AUC-ROC:\")\n",
        "    print(roc_auc_score(y_verdadero, probas))\n",
        "\n",
        "    data = pd.DataFrame({'label': y_verdadero, 'probability': probas})\n",
        "    ks = calc_ks(data)\n",
        "    print(\"KS:\")\n",
        "    print(ks)\n",
        "\n",
        "    gini = calc_gini(y_verdadero, probas)\n",
        "    print(f\"Gini: {gini}\")\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de validación\n",
        "y_val_promotor = (y_val == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_val_detractor = (y_val == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"Métricas para el modelo 'promotor':\")\n",
        "calcular_metricas(y_val_promotor, modelo_promotor.predict(X_val), probas_val_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor':\")\n",
        "calcular_metricas(y_val_detractor, modelo_detractor.predict(X_val), probas_val_detractor)\n"
      ],
      "metadata": {
        "id": "vdNKrq4ETZ8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular las importancias de las características para el modelo 'promotor'\n",
        "importances_promotor = permutation_importance(modelo_promotor, X_val, (y_val == 0).astype(int))\n",
        "\n",
        "# Crear un DataFrame con las importancias de las características para el modelo 'promotor'\n",
        "df_importancias_promotor = pd.DataFrame({\n",
        "    'variable': X.columns,\n",
        "    'importancia': importances_promotor\n",
        "})\n",
        "\n",
        "# Ordenar las características por importancia\n",
        "df_importancias_promotor = df_importancias_promotor.sort_values('importancia', ascending=False)\n",
        "\n",
        "# Convertir las importancias a porcentajes\n",
        "df_importancias_promotor['importancia'] = df_importancias_promotor['importancia'] / df_importancias_promotor['importancia'].sum() * 100\n",
        "\n",
        "# Imprimir las importancias de las características para el modelo 'promotor'\n",
        "print(\"Importancias de las características para el modelo 'promotor':\")\n",
        "print(df_importancias_promotor)\n",
        "\n",
        "\n",
        "# Calcular las importancias de las características para el modelo 'detractor'\n",
        "importances_detractor = permutation_importance(modelo_detractor, X_val, (y_val == 2).astype(int))\n",
        "\n",
        "# Crear un DataFrame con las importancias de las características para el modelo 'detractor'\n",
        "df_importancias_detractor = pd.DataFrame({\n",
        "    'variable': X.columns,\n",
        "    'importancia': importances_detractor\n",
        "})\n",
        "\n",
        "# Ordenar las características por importancia\n",
        "df_importancias_detractor = df_importancias_detractor.sort_values('importancia', ascending=False)\n",
        "\n",
        "# Convertir las importancias a porcentajes\n",
        "df_importancias_detractor['importancia'] = df_importancias_detractor['importancia'] / df_importancias_detractor['importancia'].sum() * 100\n",
        "\n",
        "# Imprimir las importancias de las características para el modelo 'detractor'\n",
        "print(\"Importancias de las características para el modelo 'detractor':\")\n",
        "print(df_importancias_detractor)\n"
      ],
      "metadata": {
        "id": "Q9mb0eYDXyCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "import numpy as np\n",
        "\n",
        "def calculate_sensitivity(model, X_val, y_val):\n",
        "    # Obtener las predicciones del modelo en los datos de validación\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # Inicializar un array de ceros para almacenar las sensibilidades de las características\n",
        "    sensitivities = np.zeros(X_val.shape[1])\n",
        "\n",
        "    # Para cada característica\n",
        "    for i in range(X_val.shape[1]):\n",
        "        # Hacer una copia de los datos de validación\n",
        "        X_val_perturbed = X_val.copy()\n",
        "        # Añadir la desviación estándar de la característica a todos los valores de esa característica\n",
        "        X_val_perturbed[:, i] += np.std(X_val[:, i])\n",
        "        # Obtener las predicciones del modelo en los datos perturbados\n",
        "        y_pred_perturbed = model.predict(X_val_perturbed)\n",
        "        # Calcular la sensibilidad de la característica como la media del valor absoluto de la diferencia\n",
        "        # entre las predicciones perturbadas y las predicciones originales\n",
        "        sensitivities[i] = np.mean(np.abs(y_pred_perturbed - y_pred))\n",
        "\n",
        "    return sensitivities\n",
        "\n",
        "# Calcular las sensibilidades de las características para el modelo 'promotor'\n",
        "sensitivities_promotor = calculate_sensitivity(modelo_promotor, X_val, (y_val == 0).astype(int))\n",
        "\n",
        "# Calcular las sensibilidades de las características para el modelo 'detractor'\n",
        "sensitivities_detractor = calculate_sensitivity(modelo_detractor, X_val, (y_val == 2).astype(int))\n",
        "\n",
        "# Crear un DataFrame con las sensibilidades de las características para el modelo 'promotor'\n",
        "df_sensitivities_promotor = pd.DataFrame({\n",
        "    'variable': X.columns,\n",
        "    'sensibilidad': sensitivities_promotor\n",
        "})\n",
        "\n",
        "# Crear un DataFrame con las sensibilidades de las características para el modelo 'detractor'\n",
        "df_sensitivities_detractor = pd.DataFrame({\n",
        "    'variable': X.columns,\n",
        "    'sensibilidad': sensitivities_detractor\n",
        "})\n",
        "\n",
        "# Ordenar las características por sensibilidad y convertir las sensibilidades a porcentajes\n",
        "df_sensitivities_promotor = df_sensitivities_promotor.sort_values('sensibilidad', ascending=False)\n",
        "df_sensitivities_promotor['sensibilidad'] = df_sensitivities_promotor['sensibilidad'] / df_sensitivities_promotor['sensibilidad'].sum() * 100\n",
        "\n",
        "df_sensitivities_detractor = df_sensitivities_detractor.sort_values('sensibilidad', ascending=False)\n",
        "df_sensitivities_detractor['sensibilidad'] = df_sensitivities_detractor['sensibilidad'] / df_sensitivities_detractor['sensibilidad'].sum() * 100\n",
        "\n",
        "# Imprimir las sensibilidades de las características para cada modelo\n",
        "print(\"Sensibilidades de las características para el modelo 'promotor':\")\n",
        "print(df_sensitivities_promotor)\n",
        "\n",
        "print(\"Sensibilidades de las características para el modelo 'detractor':\")\n",
        "print(df_sensitivities_detractor)\n"
      ],
      "metadata": {
        "id": "I-R9mTjHabkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################ real\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Esto convierte las clases 'promotor', 'neutro' y 'detractor' en 0, 1 y 2 respectivamente\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear un modelo LGBMClassifier para 'promotor' vs 'no promotor'\n",
        "y_binary_promotor = (y_train_res == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "modelo_promotor = LGBMClassifier(n_estimators=150, random_state=42)\n",
        "modelo_promotor.fit(X_train_res, y_binary_promotor)\n",
        "\n",
        "# Crear un modelo LGBMClassifier para 'detractor' vs 'no detractor'\n",
        "y_binary_detractor = (y_train_res == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "modelo_detractor = LGBMClassifier(n_estimators=150, random_state=42)\n",
        "modelo_detractor.fit(X_train_res, y_binary_detractor)\n",
        "\n",
        "# Función para calcular el valor KS\n",
        "def calc_ks(data):\n",
        "    data['good'] = (data['label'] == 0).astype(int)\n",
        "    data['bad'] = (data['label'] == 1).astype(int)\n",
        "    data['bucket'] = (data['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped = data.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob'] = grouped.max().probability\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable = kstable.reset_index()\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = np.round(((kstable.bads / data.bad.sum()).cumsum() - (kstable.goods / data.good.sum()).cumsum()), 4) * 100\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Función para calcular el coeficiente Gini\n",
        "def calc_gini(y_verdadero, y_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_verdadero, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc - 1\n",
        "    return gini\n",
        "\n",
        "# Función para calcular las métricas de rendimiento\n",
        "def calcular_metricas_binarias(y_verdadero, y_pred, probas):\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(classification_report(y_verdadero, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_verdadero, y_pred)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[i for i in np.unique(y_verdadero)],\n",
        "                         columns=[i for i in np.unique(y_verdadero)])\n",
        "    print(\"Matriz de confusión:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    print(\"Precisión del modelo:\")\n",
        "    print(accuracy_score(y_verdadero, y_pred))\n",
        "\n",
        "    print(\"Puntuación AUC-ROC:\")\n",
        "    print(roc_auc_score(y_verdadero, probas))\n",
        "\n",
        "    data = pd.DataFrame({'label': y_verdadero, 'probability': probas})\n",
        "    ks = calc_ks(data)\n",
        "    print(\"KS:\")\n",
        "    print(ks)\n",
        "\n",
        "    gini = calc_gini(y_verdadero, probas)\n",
        "    print(f\"Gini: {gini}\")\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de validación\n",
        "probas_val_promotor = modelo_promotor.predict_proba(X_val)[:, 1]\n",
        "probas_val_detractor = modelo_detractor.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de validación\n",
        "y_val_promotor = (y_val == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_val_detractor = (y_val == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"Métricas para el modelo 'promotor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_promotor, modelo_promotor.predict(X_val), probas_val_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_detractor, modelo_detractor.predict(X_val), probas_val_detractor)\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de prueba\n",
        "probas_test_promotor = modelo_promotor.predict_proba(X_test)[:, 1]\n",
        "probas_test_detractor = modelo_detractor.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de prueba\n",
        "y_test_promotor = (y_test == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_test_detractor = (y_test == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'promotor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_promotor, modelo_promotor.predict(X_test), probas_test_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_detractor, modelo_detractor.predict(X_test), probas_test_detractor)\n"
      ],
      "metadata": {
        "id": "WSX8DLltWWCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar las clases 'promotor vs no promotor' en y_val\n",
        "y_val_promotor = (y_val == le.transform(['promotor'])[0]).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "clases_y_val_promotor = np.bincount(y_val_promotor)\n",
        "print(f\"Clases 'promotor vs no promotor' en y_val: {clases_y_val_promotor}\")\n",
        "\n",
        "# Contar las clases 'detractor vs no detractor' en y_val\n",
        "y_val_detractor = (y_val == le.transform(['detractor'])[0]).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "clases_y_val_detractor = np.bincount(y_val_detractor)\n",
        "print(f\"Clases 'detractor vs no detractor' en y_val: {clases_y_val_detractor}\")\n"
      ],
      "metadata": {
        "id": "7y8Kd2h6fiJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Esto convierte las clases 'promotor', 'neutro' y 'detractor' en 0, 1 y 2 respectivamente\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear un modelo RandomForestClassifier para 'promotor' vs 'no promotor'\n",
        "y_binary_promotor = (y_train_res == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "modelo_promotor = RandomForestClassifier(n_estimators=150, random_state=42)\n",
        "modelo_promotor.fit(X_train_res, y_binary_promotor)\n",
        "\n",
        "# Crear un modelo RandomForestClassifier para 'detractor' vs 'no detractor'\n",
        "y_binary_detractor = (y_train_res == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "modelo_detractor = RandomForestClassifier(n_estimators=150, random_state=42)\n",
        "modelo_detractor.fit(X_train_res, y_binary_detractor)\n",
        "\n",
        "# Función para calcular el valor KS\n",
        "def calc_ks(data):\n",
        "    data['good'] = (data['label'] == 0).astype(int)\n",
        "    data['bad'] = (data['label'] == 1).astype(int)\n",
        "    data['bucket'] = (data['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped = data.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob'] = grouped.max().probability\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable = kstable.reset_index()\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = np.round(((kstable.bads / data.bad.sum()).cumsum() - (kstable.goods / data.good.sum()).cumsum()), 4) * 100\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Función para calcular el coeficiente Gini\n",
        "def calc_gini(y_verdadero, y_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_verdadero, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc - 1\n",
        "    return gini\n",
        "\n",
        "# Función para calcular las métricas de rendimiento\n",
        "def calcular_metricas_binarias(y_verdadero, y_pred, probas):\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(classification_report(y_verdadero, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_verdadero, y_pred)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[i for i in np.unique(y_verdadero)],\n",
        "                         columns=[i for i in np.unique(y_verdadero)])\n",
        "    print(\"Matriz de confusión:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    print(\"Precisión del modelo:\")\n",
        "    print(accuracy_score(y_verdadero, y_pred))\n",
        "\n",
        "    print(\"Puntuación AUC-ROC:\")\n",
        "    print(roc_auc_score(y_verdadero, probas))\n",
        "\n",
        "    data = pd.DataFrame({'label': y_verdadero, 'probability': probas})\n",
        "    ks = calc_ks(data)\n",
        "    print(\"KS:\")\n",
        "    print(ks)\n",
        "\n",
        "    gini = calc_gini(y_verdadero, probas)\n",
        "    print(f\"Gini: {gini}\")\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de validación\n",
        "probas_val_promotor = modelo_promotor.predict_proba(X_val)[:, 1]\n",
        "probas_val_detractor = modelo_detractor.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de validación\n",
        "y_val_promotor = (y_val == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_val_detractor = (y_val == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"Métricas para el modelo 'promotor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_promotor, modelo_promotor.predict(X_val), probas_val_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_detractor, modelo_detractor.predict(X_val), probas_val_detractor)\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de prueba\n",
        "probas_test_promotor = modelo_promotor.predict_proba(X_test)[:, 1]\n",
        "probas_test_detractor = modelo_detractor.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de prueba\n",
        "y_test_promotor = (y_test == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_test_detractor = (y_test == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'promotor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_promotor, modelo_promotor.predict(X_test), probas_test_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_detractor, modelo_detractor.predict(X_test), probas_test_detractor)\n"
      ],
      "metadata": {
        "id": "Pm_5wjwnmdmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Esto convierte las clases 'promotor', 'neutro' y 'detractor' en 0, 1 y 2 respectivamente\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear un modelo GradientBoostingClassifier para 'promotor' vs 'no promotor'\n",
        "y_binary_promotor = (y_train_res == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "modelo_promotor = GradientBoostingClassifier(n_estimators=150, random_state=42)\n",
        "modelo_promotor.fit(X_train_res, y_binary_promotor)\n",
        "\n",
        "# Crear un modelo GradientBoostingClassifier para 'detractor' vs 'no detractor'\n",
        "y_binary_detractor = (y_train_res == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "modelo_detractor = GradientBoostingClassifier(n_estimators=150, random_state=42)\n",
        "modelo_detractor.fit(X_train_res, y_binary_detractor)\n",
        "\n",
        "# Función para calcular el valor KS\n",
        "def calc_ks(data):\n",
        "    data['good'] = (data['label'] == 0).astype(int)\n",
        "    data['bad'] = (data['label'] == 1).astype(int)\n",
        "    data['bucket'] = (data['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped = data.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob'] = grouped.max().probability\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable = kstable.reset_index()\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = np.round(((kstable.bads / data.bad.sum()).cumsum() - (kstable.goods / data.good.sum()).cumsum()), 4) * 100\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Función para calcular el coeficiente Gini\n",
        "def calc_gini(y_verdadero, y_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_verdadero, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc - 1\n",
        "    return gini\n",
        "\n",
        "# Función para calcular las métricas de rendimiento\n",
        "def calcular_metricas_binarias(y_verdadero, y_pred, probas):\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(classification_report(y_verdadero, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_verdadero, y_pred)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[i for i in np.unique(y_verdadero)],\n",
        "                         columns=[i for i in np.unique(y_verdadero)])\n",
        "    print(\"Matriz de confusión:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    print(\"Precisión del modelo:\")\n",
        "    print(accuracy_score(y_verdadero, y_pred))\n",
        "\n",
        "    print(\"Puntuación AUC-ROC:\")\n",
        "    print(roc_auc_score(y_verdadero, probas))\n",
        "\n",
        "    data = pd.DataFrame({'label': y_verdadero, 'probability': probas})\n",
        "    ks = calc_ks(data)\n",
        "    print(\"KS:\")\n",
        "    print(ks)\n",
        "\n",
        "    gini = calc_gini(y_verdadero, probas)\n",
        "    print(f\"Gini: {gini}\")\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de validación\n",
        "probas_val_promotor = modelo_promotor.predict_proba(X_val)[:, 1]\n",
        "probas_val_detractor = modelo_detractor.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de validación\n",
        "y_val_promotor = (y_val == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_val_detractor = (y_val == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"Métricas para el modelo 'promotor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_promotor, modelo_promotor.predict(X_val), probas_val_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_detractor, modelo_detractor.predict(X_val), probas_val_detractor)\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de prueba\n",
        "probas_test_promotor = modelo_promotor.predict_proba(X_test)[:, 1]\n",
        "probas_test_detractor = modelo_detractor.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de prueba\n",
        "y_test_promotor = (y_test == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_test_detractor = (y_test == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'promotor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_promotor, modelo_promotor.predict(X_test), probas_test_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_detractor, modelo_detractor.predict(X_test), probas_test_detractor)\n"
      ],
      "metadata": {
        "id": "DmAYaukhyvxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Esto convierte las clases 'promotor', 'neutro' y 'detractor' en 0, 1 y 2 respectivamente\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear un modelo Sequential para 'promotor' vs 'no promotor'\n",
        "y_binary_promotor = (y_train_res == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "modelo_promotor = Sequential()\n",
        "modelo_promotor.add(Dense(32, activation='relu', input_dim=X_train_res.shape[1]))\n",
        "modelo_promotor.add(Dense(1, activation='sigmoid'))\n",
        "modelo_promotor.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "modelo_promotor.fit(X_train_res, y_binary_promotor, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Crear un modelo Sequential para 'detractor' vs 'no detractor'\n",
        "y_binary_detractor = (y_train_res == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "modelo_detractor = Sequential()\n",
        "modelo_detractor.add(Dense(32, activation='relu', input_dim=X_train_res.shape[1]))\n",
        "modelo_detractor.add(Dense(1, activation='sigmoid'))\n",
        "modelo_detractor.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "modelo_detractor.fit(X_train_res, y_binary_detractor, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Función para calcular el valor KS\n",
        "def calc_ks(data):\n",
        "    data['good'] = (data['label'] == 0).astype(int)\n",
        "    data['bad'] = (data['label'] == 1).astype(int)\n",
        "    data['bucket'] = (data['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped = data.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob'] = grouped.max().probability\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable = kstable.reset_index()\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = np.round(((kstable.bads / data.bad.sum()).cumsum() - (kstable.goods / data.good.sum()).cumsum()), 4) * 100\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Función para calcular el coeficiente Gini\n",
        "def calc_gini(y_verdadero, y_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_verdadero, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc - 1\n",
        "    return gini\n",
        "\n",
        "# Función para calcular las métricas de rendimiento\n",
        "def calcular_metricas_binarias(y_verdadero, y_pred, probas):\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(classification_report(y_verdadero, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_verdadero, y_pred)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[i for i in np.unique(y_verdadero)],\n",
        "                         columns=[i for i in np.unique(y_verdadero)])\n",
        "    print(\"Matriz de confusión:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    print(\"Precisión del modelo:\")\n",
        "    print(accuracy_score(y_verdadero, y_pred))\n",
        "\n",
        "    print(\"Puntuación AUC-ROC:\")\n",
        "    print(roc_auc_score(y_verdadero, probas))\n",
        "\n",
        "    data = pd.DataFrame({'label': y_verdadero, 'probability': probas})\n",
        "    ks = calc_ks(data)\n",
        "    print(\"KS:\")\n",
        "    print(ks)\n",
        "\n",
        "    gini = calc_gini(y_verdadero, probas)\n",
        "    print(f\"Gini: {gini}\")\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de validación\n",
        "probas_val_promotor = modelo_promotor.predict_proba(X_val)[:, 1]\n",
        "probas_val_detractor = modelo_detractor.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de validación\n",
        "y_val_promotor = (y_val == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_val_detractor = (y_val == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"Métricas para el modelo 'promotor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_promotor, (probas_val_promotor > 0.5).astype(int), probas_val_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_detractor, (probas_val_detractor > 0.5).astype(int), probas_val_detractor)\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de prueba\n",
        "probas_test_promotor = modelo_promotor.predict_proba(X_test)[:, 1]\n",
        "probas_test_detractor = modelo_detractor.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de prueba\n",
        "y_test_promotor = (y_test == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_test_detractor = (y_test == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'promotor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_promotor, (probas_test_promotor > 0.5).astype(int), probas_test_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_detractor, (probas_test_detractor > 0.5).astype(int), probas_test_detractor)\n"
      ],
      "metadata": {
        "id": "HCK9Wy0g6Q6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)  # Esto convierte las clases 'promotor', 'neutro' y 'detractor' en 0, 1 y 2 respectivamente\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Aplicar SMOTE al conjunto de entrenamiento\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Crear un modelo AdaBoostClassifier para 'promotor' vs 'no promotor'\n",
        "y_binary_promotor = (y_train_res == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "modelo_promotor = AdaBoostClassifier(n_estimators=150, random_state=42)\n",
        "modelo_promotor.fit(X_train_res, y_binary_promotor)\n",
        "\n",
        "# Crear un modelo AdaBoostClassifier para 'detractor' vs 'no detractor'\n",
        "y_binary_detractor = (y_train_res == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "modelo_detractor = AdaBoostClassifier(n_estimators=150, random_state=42)\n",
        "modelo_detractor.fit(X_train_res, y_binary_detractor)\n",
        "\n",
        "# Función para calcular el valor KS\n",
        "def calc_ks(data):\n",
        "    data['good'] = (data['label'] == 0).astype(int)\n",
        "    data['bad'] = (data['label'] == 1).astype(int)\n",
        "    data['bucket'] = (data['probability'].rank(pct=True)*10).astype(int)\n",
        "    grouped = data.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().probability.to_frame(name='min_prob')\n",
        "    kstable['max_prob'] = grouped.max().probability\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable = kstable.reset_index()\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = np.round(((kstable.bads / data.bad.sum()).cumsum() - (kstable.goods / data.good.sum()).cumsum()), 4) * 100\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Función para calcular el coeficiente Gini\n",
        "def calc_gini(y_verdadero, y_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_verdadero, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc - 1\n",
        "    return gini\n",
        "\n",
        "# Función para calcular las métricas de rendimiento\n",
        "def calcular_metricas_binarias(y_verdadero, y_pred, probas):\n",
        "    print(\"Informe de clasificación:\")\n",
        "    print(classification_report(y_verdadero, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_verdadero, y_pred)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[i for i in np.unique(y_verdadero)],\n",
        "                         columns=[i for i in np.unique(y_verdadero)])\n",
        "    print(\"Matriz de confusión:\")\n",
        "    print(cm_df)\n",
        "\n",
        "    print(\"Precisión del modelo:\")\n",
        "    print(accuracy_score(y_verdadero, y_pred))\n",
        "\n",
        "    print(\"Puntuación AUC-ROC:\")\n",
        "    print(roc_auc_score(y_verdadero, probas))\n",
        "\n",
        "    data = pd.DataFrame({'label': y_verdadero, 'probability': probas})\n",
        "    ks = calc_ks(data)\n",
        "    print(\"KS:\")\n",
        "    print(ks)\n",
        "\n",
        "    gini = calc_gini(y_verdadero, probas)\n",
        "    print(f\"Gini: {gini}\")\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de validación\n",
        "probas_val_promotor = modelo_promotor.predict_proba(X_val)[:, 1]\n",
        "probas_val_detractor = modelo_detractor.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de validación\n",
        "y_val_promotor = (y_val == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_val_detractor = (y_val == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"Métricas para el modelo 'promotor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_promotor, (probas_val_promotor > 0.5).astype(int), probas_val_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de validación:\")\n",
        "calcular_metricas_binarias(y_val_detractor, (probas_val_detractor > 0.5).astype(int), probas_val_detractor)\n",
        "\n",
        "# Obtener las probabilidades de las predicciones en el conjunto de prueba\n",
        "probas_test_promotor = modelo_promotor.predict_proba(X_test)[:, 1]\n",
        "probas_test_detractor = modelo_detractor.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular las métricas de rendimiento en el conjunto de prueba\n",
        "y_test_promotor = (y_test == 0).astype(int)  # Esto convierte la clase 'promotor' en 1 y las demás en 0\n",
        "y_test_detractor = (y_test == 2).astype(int)  # Esto convierte la clase 'detractor' en 1 y las demás en 0\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'promotor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_promotor, (probas_test_promotor > 0.5).astype(int), probas_test_promotor)\n",
        "\n",
        "print(\"\\nMétricas para el modelo 'detractor' en el conjunto de prueba:\")\n",
        "calcular_metricas_binarias(y_test_detractor, (probas_test_detractor > 0.5).astype(int), probas_test_detractor)\n"
      ],
      "metadata": {
        "id": "fY5QSpu9XEWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.stat import ChiSquareTest\n",
        "\n",
        "# Asumiendo que 'df' es tu DataFrame y 'nueva' e 'incumplimiento' son tus columnas\n",
        "\n",
        "# Primero necesitamos convertir las columnas categóricas a numéricas\n",
        "indexer = StringIndexer(inputCol=\"nueva\", outputCol=\"nuevaIndexada\")\n",
        "df = indexer.fit(df).transform(df)\n",
        "\n",
        "# Ahora realizamos la prueba de Chi cuadrado\n",
        "r = ChiSquareTest.test(df, \"nuevaIndexada\", \"incumplimiento\").head()\n",
        "\n",
        "print(\"pValues: \" + str(r.pValues))\n",
        "print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
        "print(\"statistics: \" + str(r.statistics))\n"
      ],
      "metadata": {
        "id": "Fvq3F-RWh9Gm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}