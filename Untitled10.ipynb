{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCfKij7epbwgWmRQXEIw1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristValen/Acciones-RNR/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "predictions_train = model.transform(train)\n",
        "\n",
        "# Calculate ROC-AUC and accuracy metrics for training data\n",
        "evaluator_train_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc_train = evaluator_train_roc_auc.evaluate(predictions_train)\n",
        "evaluator_train_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_train = evaluator_train_accuracy.evaluate(predictions_train)\n",
        "\n",
        "print(f\"Training ROC-AUC: {roc_auc_train:.3f}\")\n",
        "print(f\"Training Accuracy: {accuracy_train:.3f}\")\n",
        "\n",
        "# Calculate the confusion matrix for training data\n",
        "predictionAndLabels_train = predictions_train.select(\"prediction\", \"label\").rdd\n",
        "metrics_train = MulticlassMetrics(predictionAndLabels_train)\n",
        "confusion_matrix_train = metrics_train.confusionMatrix().toArray()\n",
        "print(f\"Training Confusion matrix:\\n{confusion_matrix_train}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for training data\n",
        "TP_train = confusion_matrix_train[1, 1]\n",
        "FP_train = confusion_matrix_train[0, 1]\n",
        "FN_train = confusion_matrix_train[1, 0]\n",
        "precision_manual_train = TP_train / (TP_train + FP_train)\n",
        "recall_manual_train = TP_train / (TP_train + FN_train)\n",
        "f1_manual_train = 2 * (precision_manual_train * recall_manual_train) / (precision_manual_train + recall_manual_train)\n",
        "print(f\"Training Recall (manually calculated): {recall_manual_train:.3f}\")\n",
        "print(f\"Training F1 (manually calculated): {f1_manual_train:.3f}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Define a user-defined function to extract the probability of class 1\n",
        "extract_probability = udf(lambda v: float(v[1]), DoubleType())\n",
        "\n",
        "# Create a new column with the probability of class 1 in the predictions DataFrame\n",
        "predictions_train = predictions_train.withColumn('score', extract_probability('probability'))\n",
        "\n",
        "# Calculate the KS statistic for the training data\n",
        "ks_value = calc_ks(predictions_train)\n",
        "print(f\"Training KS: {ks_value:.3f}\")\n"
      ],
      "metadata": {
        "id": "dFZABeDLL0ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf, when, percent_rank\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "predictions_train = model.transform(train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions_test = model.transform(test)\n",
        "\n",
        "# Create a UDF to extract the score from the probability column\n",
        "def extract_score(vector):\n",
        "    return float(vector[1])\n",
        "\n",
        "extract_score_udf = udf(extract_score, DoubleType())\n",
        "\n",
        "# Create the score column in the predictions DataFrames\n",
        "predictions_train = predictions_train.withColumn('score', extract_score_udf('probability'))\n",
        "predictions_test = predictions_test.withColumn('score', extract_score_udf('probability'))\n",
        "\n",
        "# Convert the predictions to an RDD and calculate metrics using MulticlassMetrics\n",
        "predictionAndLabels_train = predictions_train.select(\"prediction\", \"label\").rdd\n",
        "metrics_train = MulticlassMetrics(predictionAndLabels_train)\n",
        "confusion_matrix_train = metrics_train.confusionMatrix().toArray()\n",
        "print(f\"Training Confusion matrix:\\n{confusion_matrix_train}\")\n",
        "\n",
        "predictionAndLabels_test = predictions_test.select(\"prediction\", \"label\").rdd\n",
        "metrics_test = MulticlassMetrics(predictionAndLabels_test)\n",
        "confusion_matrix_test = metrics_test.confusionMatrix().toArray()\n",
        "print(f\"Test Confusion matrix:\\n{confusion_matrix_test}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for training data\n",
        "TP_train = confusion_matrix_train[1, 1]\n",
        "FP_train = confusion_matrix_train[0, 1]\n",
        "FN_train = confusion_matrix_train[1, 0]\n",
        "\n",
        "precision_train = TP_train / (TP_train + FP_train)\n",
        "recall_train = TP_train / (TP_train + FN_train)\n",
        "f1_score_train = 2 * (precision_train * recall_train) / (precision_train + recall_train)\n",
        "\n",
        "print(f\"Training Precision: {precision_train}\")\n",
        "print(f\"Training Recall: {recall_train}\")\n",
        "print(f\"Training F1 Score: {f1_score_train}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for test data\n",
        "TP_test = confusion_matrix_test[1, 1]\n",
        "FP_test = confusion_matrix_test[0, 1]\n",
        "FN_test = confusion_matrix_test[1, 0]\n",
        "\n",
        "precision_test = TP_test / (TP_test + FP_test)\n",
        "recall_test = TP_test / (TP_test + FN_test)\n",
        "f1_score_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n",
        "\n",
        "print(f\"Test Precision: {precision_test}\")\n",
        "print(f\"Test Recall: {recall_test}\")\n",
        "print(f\"Test F1 Score: {f1_score_test}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.withColumn('good', when(col('label') == 0, 1).otherwise(0)) \\\n",
        "                .withColumn('bad', when(col('label') == 1, 1).otherwise(0)) \\\n",
        "                .withColumn('bucket', (percent_rank().over(Window.orderBy('score'))*10).cast(IntegerType()))\n",
        "    grouped=data_pd.groupBy('bucket')\n",
        "    kstable=grouped.agg(min(col('score')).alias('min_score'), max(col('score')).alias('max_score'), sum(col('bad')).alias('bads'), sum(col('good')).alias('goods'))\n",
        "    kstable=kstable.withColumn('bad_rate', col('bads')/(col('bads')+col('goods')))\n",
        "    kstable=kstable.withColumn('ks', (sum(col('bads')).over(Window.orderBy('bucket'))/kstable.select(sum(col('bads'))).collect()[0][0])-(sum(col('goods')).over(Window.orderBy('bucket'))/kstable.select(sum(col('goods'))).collect()[0][0]))\n",
        "    ks_value=kstable.select(max(abs(col('ks')))).collect()[0][0]\n",
        "    return ks_value\n",
        "\n",
        "ks_value_train=calc_ks(predictions_train)\n",
        "ks_value_test=calc_ks(predictions_test)\n",
        "\n",
        "print(f\"Training KS: {ks_value_train}\")\n",
        "print(f\"Test KS: {ks_value_test}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "f9YfrL0s59ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from pyspark.sql import Row\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the Spark DataFrame to a Pandas DataFrame\n",
        "data_pd = df_2.toPandas()\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in data_pd.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "X = data_pd[feature_cols].values\n",
        "y = data_pd['Malo_Dias_tot'].values\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Create a SMOTE object\n",
        "smote = SMOTE(random_state=random_state)\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(random_state=random_state)\n",
        "\n",
        "# Create a pipeline to chain SMOTE and Decision Tree together\n",
        "pipeline = Pipeline([('smote', smote), ('dt', dt)])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Perform SMOTE oversampling on the test data\n",
        "X_test_resampled, y_test_resampled = smote.fit_resample(X_test, y_test)\n",
        "\n",
        "# Predict values for the oversampled test set\n",
        "y_pred = model.predict(X_train_resampled)\n",
        "\n",
        "# Calculate metrics\n",
        "tn, fp, fn, tp = confusion_matrix(y_train_resampled, y_pred).ravel()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = accuracy_score(y_train_resampled, y_pred)\n",
        "precision = precision_score(y_train_resampled, y_pred)\n",
        "recall = recall_score(y_train_resampled, y_pred)\n",
        "f1_score = f1_score(y_train_resampled, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Convert the true labels and predicted scores to int data type\n",
        "y_train_resampled = y_train_resampled.astype(int)\n",
        "y_pred = y_pred.astype(int)\n",
        "\n",
        "# Create a list of Row objects containing the true labels and predicted scores\n",
        "rows = [Row(label=int(label), score=int(score)) for label, score in zip(y_train_resampled, y_pred)]\n",
        "\n",
        "# Convert the list of Row objects to a PySpark DataFrame\n",
        "predictions_train = spark.createDataFrame(rows)\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.withColumn('good', when(col('label') == 0, 1).otherwise(0)) \\\n",
        "                .withColumn('bad', when(col('label') == 1, 1).otherwise(0)) \\\n",
        "                .withColumn('bucket', (percent_rank().over(Window.orderBy('score'))*10).cast(IntegerType()))\n",
        "    grouped=data_pd.groupBy('bucket')\n",
        "    kstable=grouped.agg(min(col('score')).alias('min_score'), max(col('score')).alias('max_score'), sum(col('bad')).alias('bads'), sum(col('good')).alias('goods'))\n",
        "    kstable=kstable.withColumn('bad_rate', col('bads')/(col('bads')+col('goods')))\n",
        "    kstable=kstable.withColumn('ks', (sum(col('bads')).over(Window.orderBy('bucket'))/kstable.select(sum(col('bads'))).collect()[0][0])-(sum(col('goods')).over(Window.orderBy('bucket'))/kstable.select(sum(col('goods'))).collect()[0][0]))\n",
        "    ks_value=kstable.select(max(abs(col('ks')))).collect()[0][0]\n",
        "    return ks_value\n",
        "\n",
        "ks_value_train=calc_ks(predictions_train)\n",
        "\n",
        "print(f\"Training KS: {ks_value_train}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nscpUVuClnLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### con funcion\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = cv.fit(train)\n",
        "\n",
        "def calculate_metrics(predictions):\n",
        "    # Calculate ROC-AUC and accuracy metrics\n",
        "    evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "    roc_auc = evaluator_roc_auc.evaluate(predictions)\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "    metrics = MulticlassMetrics(predictionAndLabels)\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    # Manually calculate recall and F1 score\n",
        "    TP = confusion_matrix[1, 1]\n",
        "    FP = confusion_matrix[0, 1]\n",
        "    FN = confusion_matrix[1, 0]\n",
        "    precision_manual = TP / (TP + FP)\n",
        "    recall_manual = TP / (TP + FN)\n",
        "    f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "\n",
        "    return roc_auc, accuracy, precision_manual, recall_manual, f1_manual, confusion_matrix\n",
        "\n",
        "# Make predictions on the training data and calculate metrics for training data\n",
        "predictions_train = model.transform(train)\n",
        "train_roc_auc, train_accuracy, train_precision, train_recall, train_f1Score, train_confusion_matrix = calculate_metrics(predictions_train)\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training ROC-AUC: {train_roc_auc:.3f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Training Precision: {train_precision:.3f}\")\n",
        "print(f\"Training Recall: {train_recall:.3f}\")\n",
        "print(f\"Training F1: {train_f1Score:.3f}\")\n",
        "print(f\"Training Confusion matrix:\\n{train_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the test data and calculate metrics for test data\n",
        "predictions_test = model.transform(test)\n",
        "test_roc_auc, test_accuracy, test_precision, test_recall, test_f1Score, test_confusion_matrix = calculate_metrics(predictions_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Test Precision: {test_precision:.3f}\")\n",
        "print(f\"Test Recall: {test_recall:.3f}\")\n",
        "print(f\"Test F1: {test_f1Score:.3f}\")\n",
        "print(f\"Test Confusion matrix:\\n{test_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the df_oot data and calculate metrics for df_oot data\n",
        "predictions_oot = model.transform(df_oot)\n",
        "oot_roc_auc, oot_accuracy, oot_precision, oot_recall, oot_f1Score, oot_confusion_matrix = calculate_metrics(predictions_oot)\n",
        "\n",
        "# Print df_oot metrics\n",
        "print(f\"df_oot ROC-AUC: {oot_roc_auc:.3f}\")\n",
        "print(f\"df_oot Accuracy: {oot_accuracy:.3f}\")\n",
        "print(f\"df_oot Precision: {oot_precision:.3f}\")\n",
        "print(f\"df_oot Recall: {oot_recall:.3f}\")\n",
        "print(f\"df_oot F1: {oot_f1Score:.3f}\")\n",
        "print(f\"df_oot Confusion matrix:\\n{oot_confusion_matrix}\")\n"
      ],
      "metadata": {
        "id": "1LnrmAvvodnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Establecer la semilla para el generador de números aleatorios\n",
        "random_state = 0\n",
        "\n",
        "# Calcular el número de ejemplos en cada clase\n",
        "class_counts = df_2.groupBy('Malo_Dias_tot').count().collect()\n",
        "num_positives = class_counts[1][1]\n",
        "num_negatives = class_counts[0][1]\n",
        "\n",
        "# Calcular el número de ejemplos negativos a mantener\n",
        "num_to_keep = int(num_positives / num_negatives * num_negatives)\n",
        "\n",
        "# Seleccionar un subconjunto aleatorio de la clase mayoritaria\n",
        "majority_subset = df_2.filter(col('Malo_Dias_tot') == 0).orderBy(rand(seed=random_state)).limit(num_to_keep)\n",
        "\n",
        "# Combinar el subconjunto mayoritario con la clase minoritaria para crear los datos submuestreados\n",
        "undersampled_data = majority_subset.union(df_2.filter(col('Malo_Dias_tot') == 1))\n",
        "\n",
        "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "train, test = undersampled_data.randomSplit([0.7, 0.3], seed=random_state)\n",
        "\n",
        "# Definir las columnas de características\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Crear un VectorAssembler para combinar las columnas de características en una sola columna vectorial\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Crear un StandardScaler para estandarizar las características\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
        "\n",
        "# Entrenar el modelo de Máquina de Vectores de Soporte sin validación cruzada\n",
        "svm = LinearSVC(featuresCol='scaledFeatures', labelCol='Malo_Dias_tot', maxIter=10, regParam=0.1)\n",
        "\n",
        "# Crear un pipeline para encadenar el ensamblador, el escalador y el SVM juntos\n",
        "pipeline = Pipeline(stages=[assembler, scaler, svm])\n",
        "\n",
        "# Ajustar el pipeline a los datos de entrenamiento\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "\n",
        "def calculate_metrics(predictions):\n",
        "    # Calculate ROC-AUC and accuracy metrics\n",
        "    evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "    roc_auc = evaluator_roc_auc.evaluate(predictions)\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "    metrics = MulticlassMetrics(predictionAndLabels)\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    # Manually calculate recall and F1 score\n",
        "    TP = confusion_matrix[1, 1]\n",
        "    FP = confusion_matrix[0, 1]\n",
        "    FN = confusion_matrix[1, 0]\n",
        "    precision_manual = TP / (TP + FP)\n",
        "    recall_manual = TP / (TP + FN)\n",
        "    f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "\n",
        "    return roc_auc, accuracy, precision_manual, recall_manual, f1_manual, confusion_matrix\n",
        "\n",
        "# Make predictions on the training data and calculate metrics for training data\n",
        "predictions_train = model.transform(train)\n",
        "train_roc_auc, train_accuracy, train_precision, train_recall, train_f1Score, train_confusion_matrix = calculate_metrics(predictions_train)\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training ROC-AUC: {train_roc_auc:.3f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Training Precision: {train_precision:.3f}\")\n",
        "print(f\"Training Recall: {train_recall:.3f}\")\n",
        "print(f\"Training F1: {train_f1Score:.3f}\")\n",
        "print(f\"Training Confusion matrix:\\n{train_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the test data and calculate metrics for test data\n",
        "predictions_test = model.transform(test)\n",
        "test_roc_auc, test_accuracy, test_precision, test_recall, test_f1Score, test_confusion_matrix = calculate_metrics(predictions_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Test Precision: {test_precision:.3f}\")\n",
        "print(f\"Test Recall: {test_recall:.3f}\")\n",
        "print(f\"Test F1: {test_f1Score:.3f}\")\n",
        "print(f\"Test Confusion matrix:\\n{test_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the df_oot data and calculate metrics for df_oot data\n",
        "predictions_oot = model.transform(df_oot)\n",
        "oot_roc_auc, oot_accuracy, oot_precision, oot_recall, oot_f1Score, oot_confusion_matrix = calculate_metrics(predictions_oot)\n",
        "\n",
        "# Print df_oot metrics\n",
        "print(f\"df_oot ROC-AUC: {oot_roc_auc:.3f}\")\n",
        "print(f\"df_oot Accuracy: {oot_accuracy:.3f}\")\n",
        "print(f\"df_oot Precision: {oot_precision:.3f}\")\n",
        "print(f\"df_oot Recall: {oot_recall:.3f}\")\n",
        "print(f\"df_oot F1: {oot_f1Score:.3f}\")\n",
        "print(f\"df_oot Confusion matrix:\\n{oot_confusion_matrix}\")\n",
        "\n",
        "#no reproducible"
      ],
      "metadata": {
        "id": "NTin1c3Q5xZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#intentar que sea reproducible\n",
        "random_state = 0\n",
        "\n",
        "# Calcular el número de ejemplos en cada clase\n",
        "class_counts = df_2.groupBy('Malo_Dias_tot').count().collect()\n",
        "num_positives = class_counts[1][1]\n",
        "num_negatives = class_counts[0][1]\n",
        "\n",
        "# Calcular el número de ejemplos negativos a mantener\n",
        "num_to_keep = int(num_positives / num_negatives * num_negatives)\n",
        "\n",
        "# Seleccionar un subconjunto aleatorio de la clase mayoritaria\n",
        "majority_subset = df_2.filter(col('Malo_Dias_tot') == 0).orderBy(rand(seed=random_state)).limit(num_to_keep)\n",
        "\n",
        "# Combinar el subconjunto mayoritario con la clase minoritaria para crear los datos submuestreados\n",
        "undersampled_data = majority_subset.union(df_2.filter(col('Malo_Dias_tot') == 1))\n",
        "\n",
        "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "train, test = undersampled_data.randomSplit([0.7, 0.3], seed=random_state)\n",
        "\n",
        "# Definir las columnas de características\n",
        "feature_cols = [col for col in train.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Crear un VectorAssembler para combinar las columnas de características en una sola columna vectorial\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "\n",
        "# Crear un StandardScaler para estandarizar las características\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
        "\n",
        "# Entrenar el modelo de Máquina de Vectores de Soporte sin validación cruzada\n",
        "svm = LinearSVC(featuresCol='scaledFeatures', labelCol='Malo_Dias_tot', maxIter=10, regParam=0.1)\n",
        "\n",
        "# Crear un pipeline para encadenar el ensamblador, el escalador y el SVM juntos\n",
        "pipeline = Pipeline(stages=[assembler, scaler, svm])\n",
        "\n",
        "# Ajustar el pipeline a los datos de entrenamiento\n",
        "model = pipeline.fit(train)\n",
        "\n",
        "\n",
        "def calculate_metrics(predictions):\n",
        "    # Calculate ROC-AUC and accuracy metrics\n",
        "    evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "    roc_auc = evaluator_roc_auc.evaluate(predictions)\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "    metrics = MulticlassMetrics(predictionAndLabels)\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    # Manually calculate recall and F1 score\n",
        "    TP = confusion_matrix[1, 1]\n",
        "    FP = confusion_matrix[0, 1]\n",
        "    FN = confusion_matrix[1, 0]\n",
        "    precision_manual = TP / (TP + FP)\n",
        "    recall_manual = TP / (TP + FN)\n",
        "    f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "\n",
        "    return roc_auc, accuracy, precision_manual, recall_manual, f1_manual, confusion_matrix\n",
        "\n",
        "# Make predictions on the training data and calculate metrics for training data\n",
        "predictions_train = model.transform(train)\n",
        "train_roc_auc, train_accuracy, train_precision, train_recall, train_f1Score, train_confusion_matrix = calculate_metrics(predictions_train)\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training ROC-AUC: {train_roc_auc:.3f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Training Precision: {train_precision:.3f}\")\n",
        "print(f\"Training Recall: {train_recall:.3f}\")\n",
        "print(f\"Training F1: {train_f1Score:.3f}\")\n",
        "print(f\"Training Confusion matrix:\\n{train_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the test data and calculate metrics for test data\n",
        "predictions_test = model.transform(test)\n",
        "test_roc_auc, test_accuracy, test_precision, test_recall, test_f1Score, test_confusion_matrix = calculate_metrics(predictions_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Test Precision: {test_precision:.3f}\")\n",
        "print(f\"Test Recall: {test_recall:.3f}\")\n",
        "print(f\"Test F1: {test_f1Score:.3f}\")\n",
        "print(f\"Test Confusion matrix:\\n{test_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the df_oot data and calculate metrics for df_oot data\n",
        "predictions_oot = model.transform(df_oot)\n",
        "oot_roc_auc, oot_accuracy, oot_precision, oot_recall, oot_f1Score, oot_confusion_matrix = calculate_metrics(predictions_oot)\n",
        "\n",
        "# Print df_oot metrics\n",
        "print(f\"df_oot ROC-AUC: {oot_roc_auc:.3f}\")\n",
        "print(f\"df_oot Accuracy: {oot_accuracy:.3f}\")\n",
        "print(f\"df_oot Precision: {oot_precision:.3f}\")\n",
        "print(f\"df_oot Recall: {oot_recall:.3f}\")\n",
        "print(f\"df_oot F1: {oot_f1Score:.3f}\")\n",
        "print(f\"df_oot Confusion matrix:\\n{oot_confusion_matrix}\")\n"
      ],
      "metadata": {
        "id": "qhFGWQDf_0rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Rename the label column and cast it to DoubleType\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in df8.columns if col != 'label']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "train = assembler.transform(train)\n",
        "test = assembler.transform(test)\n",
        "\n",
        "# Convert the train and test DataFrames to Pandas DataFrames\n",
        "train_pd = train.toPandas()\n",
        "test_pd = test.toPandas()\n",
        "\n",
        "# Create a SMOTE object\n",
        "smote = SMOTE(random_state=seed)\n",
        "\n",
        "# Perform SMOTE oversampling on the train and test data\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(train_pd[feature_cols], train_pd['label'])\n",
        "X_test_resampled, y_test_resampled = smote.fit_resample(test_pd[feature_cols], test_pd['label'])\n",
        "\n",
        "# Convert the resampled train and test data back to Spark DataFrames\n",
        "train_resampled_pd = pd.concat([pd.DataFrame(X_train_resampled, columns=feature_cols), pd.Series(y_train_resampled, name='label')], axis=1)\n",
        "train_resampled = spark.createDataFrame(train_resampled_pd)\n",
        "train_resampled = assembler.transform(train_resampled)\n",
        "\n",
        "test_resampled_pd = pd.concat([pd.DataFrame(X_test_resampled, columns=feature_cols), pd.Series(y_test_resampled, name='label')], axis=1)\n",
        "test_resampled = spark.createDataFrame(test_resampled_pd)\n",
        "test_resampled = assembler.transform(test_resampled)\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(seed=seed)\n",
        "\n",
        "# Fit the model to the resampled training data\n",
        "model = dt.fit(train_resampled)\n",
        "\n",
        "def calculate_metrics(predictions):\n",
        "    # Calculate ROC-AUC and accuracy metrics\n",
        "    evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "    roc_auc = evaluator_roc_auc.evaluate(predictions)\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "    metrics = MulticlassMetrics(predictionAndLabels)\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    # Manually calculate recall and F1 score\n",
        "    TP = confusion_matrix[1, 1]\n",
        "    FP = confusion_matrix[0, 1]\n",
        "    FN = confusion_matrix[1, 0]\n",
        "    precision_manual = TP / (TP + FP)\n",
        "    recall_manual = TP / (TP + FN)\n",
        "    f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "\n",
        "    return roc_auc, accuracy, precision_manual, recall_manual, f1_manual, confusion_matrix\n",
        "\n",
        "# Make predictions on the resampled training data and calculate metrics for training data\n",
        "predictions_train = model.transform(train_resampled)\n",
        "train_roc_auc, train_accuracy, train_precision, train_recall, train_f1Score, train_confusion_matrix = calculate_metrics(predictions_train)\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training ROC-AUC: {train_roc_auc:.3f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Training Precision: {train_precision:.3f}\")\n",
        "print(f\"Training Recall: {train_recall:.3f}\")\n",
        "print(f\"Training F1: {train_f1Score:.3f}\")\n",
        "print(f\"Training Confusion matrix:\\n{train_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the resampled test data and calculate metrics for test data\n",
        "predictions_test = model.transform(test_resampled)\n",
        "test_roc_auc, test_accuracy, test_precision, test_recall, test_f1Score, test_confusion_matrix = calculate_metrics(predictions_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Test Precision: {test_precision:.3f}\")\n",
        "print(f\"Test Recall: {test_recall:.3f}\")\n",
        "print(f\"Test F1: {test_f1Score:.3f}\")\n",
        "print(f\"Test Confusion matrix:\\n{test_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature matrix and label vector for df_oot2\n",
        "df_oot2 = assembler.transform(df_oot2)\n",
        "\n",
        "# Make predictions on the df_oot2 data and calculate metrics for df_oot2 data\n",
        "predictions_oot2 = model.transform(df_oot2)\n",
        "oot2_roc_auc, oot2_accuracy, oot2_precision, oot2_recall, oot2_f1Score, oot2_confusion_matrix = calculate_metrics(predictions_oot2)\n",
        "\n",
        "# Print df_oot2 metrics\n",
        "print(f\"df_oot2 ROC-AUC: {oot2_roc_auc:.3f}\")\n",
        "print(f\"df_oot2 Accuracy: {oot2_accuracy:.3f}\")\n",
        "print(f\"df_oot2 Precision: {oot2_precision:.3f}\")\n",
        "print(f\"df_oot2 Recall: {oot2_recall:.3f}\")\n",
        "print(f\"df_oot2 F1: {oot2_f1Score:.3f}\")\n",
        "print(f\"df_oot2 Confusion matrix:\\n{oot2_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature importances from the trained model\n",
        "importances = model.featureImportances\n",
        "\n",
        "# Create a dictionary of feature names and their importances\n",
        "importance_dict = dict(zip(feature_cols, importances))\n",
        "\n",
        "# Sort the dictionary by importance in descending order\n",
        "sorted_importance_dict = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the top 10 most important features and their importance values\n",
        "top_10_features = sorted_importance_dict[:10]\n",
        "\n",
        "# Print the top 10 most important features and their importance values\n",
        "print(\"Top 10 most important features:\")\n",
        "for feature, importance in top_10_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-OcxNxE7dEQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Rename the label column and cast it to DoubleType\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in df8.columns if col != 'label']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "train = assembler.transform(train)\n",
        "test = assembler.transform(test)\n",
        "\n",
        "# Convert the train and test DataFrames to Pandas DataFrames\n",
        "train_pd = train.toPandas()\n",
        "test_pd = test.toPandas()\n",
        "\n",
        "# Create an ADASYN object\n",
        "adasyn = ADASYN(random_state=seed)\n",
        "\n",
        "# Perform ADASYN oversampling on the train and test data\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(train_pd[feature_cols], train_pd['label'])\n",
        "X_test_resampled, y_test_resampled = adasyn.fit_resample(test_pd[feature_cols], test_pd['label'])\n",
        "\n",
        "# Convert the resampled train and test data back to Spark DataFrames\n",
        "train_resampled_pd = pd.concat([pd.DataFrame(X_train_resampled, columns=feature_cols), pd.Series(y_train_resampled, name='label')], axis=1)\n",
        "train_resampled = spark.createDataFrame(train_resampled_pd)\n",
        "train_resampled = assembler.transform(train_resampled)\n",
        "\n",
        "test_resampled_pd = pd.concat([pd.DataFrame(X_test_resampled, columns=feature_cols), pd.Series(y_test_resampled, name='label')], axis=1)\n",
        "test_resampled = spark.createDataFrame(test_resampled_pd)\n",
        "test_resampled = assembler.transform(test_resampled)\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(seed=seed)\n",
        "\n",
        "# Fit the model to the resampled training data\n",
        "model = dt.fit(train_resampled)\n",
        "\n",
        "def calculate_metrics(predictions):\n",
        "    # Calculate ROC-AUC and accuracy metrics\n",
        "    evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "    roc_auc = evaluator_roc_auc.evaluate(predictions)\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "    metrics = MulticlassMetrics(predictionAndLabels)\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    # Manually calculate recall and F1 score\n",
        "    TP = confusion_matrix[1, 1]\n",
        "    FP = confusion_matrix[0, 1]\n",
        "    FN = confusion_matrix[1, 0]\n",
        "    precision_manual = TP / (TP + FP)\n",
        "    recall_manual = TP / (TP + FN)\n",
        "    f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "\n",
        "    return roc_auc, accuracy, precision_manual, recall_manual, f1_manual, confusion_matrix\n",
        "\n",
        "# Make predictions on the resampled training data and calculate metrics for training data\n",
        "predictions_train = model.transform(train_resampled)\n",
        "train_roc_auc, train_accuracy, train_precision, train_recall, train_f1Score, train_confusion_matrix = calculate_metrics(predictions_train)\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training ROC-AUC: {train_roc_auc:.3f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Training Precision: {train_precision:.3f}\")\n",
        "print(f\"Training Recall: {train_recall:.3f}\")\n",
        "print(f\"Training F1: {train_f1Score:.3f}\")\n",
        "print(f\"Training Confusion matrix:\\n{train_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the resampled test data and calculate metrics for test data\n",
        "predictions_test = model.transform(test_resampled)\n",
        "test_roc_auc, test_accuracy, test_precision, test_recall, test_f1Score, test_confusion_matrix = calculate_metrics(predictions_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Test Precision: {test_precision:.3f}\")\n",
        "print(f\"Test Recall: {test_recall:.3f}\")\n",
        "print(f\"Test F1: {test_f1Score:.3f}\")\n",
        "print(f\"Test Confusion matrix:\\n{test_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature matrix and label vector for df_oot2\n",
        "df_oot2 = assembler.transform(df_oot2)\n",
        "\n",
        "# Make predictions on the df_oot2 data and calculate metrics for df_oot2 data\n",
        "predictions_oot2 = model.transform(df_oot2)\n",
        "oot2_roc_auc, oot2_accuracy, oot2_precision, oot2_recall, oot2_f1Score, oot2_confusion_matrix = calculate_metrics(predictions_oot2)\n",
        "\n",
        "# Print df_oot2 metrics\n",
        "print(f\"df_oot2 ROC-AUC: {oot2_roc_auc:.3f}\")\n",
        "print(f\"df_oot2 Accuracy: {oot2_accuracy:.3f}\")\n",
        "print(f\"df_oot2 Precision: {oot2_precision:.3f}\")\n",
        "print(f\"df_oot2 Recall: {oot2_recall:.3f}\")\n",
        "print(f\"df_oot2 F1: {oot2_f1Score:.3f}\")\n",
        "print(f\"df_oot2 Confusion matrix:\\n{oot2_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature importances from the trained model\n",
        "importances = model.featureImportances\n",
        "\n",
        "# Create a dictionary of feature names and their importances\n",
        "importance_dict = dict(zip(feature_cols, importances))\n",
        "\n",
        "# Sort the dictionary by importance in descending order\n",
        "sorted_importance_dict = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the top 10 most important features and their importance values\n",
        "top_10_features = sorted_importance_dict[:10]\n",
        "\n",
        "# Print the top 10 most important features and their importance values\n",
        "print(\"Top 10 most important features:\")\n",
        "for feature, importance in top_10_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ],
      "metadata": {
        "id": "m8yxrhx7DtUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Rename the label column and cast it to DoubleType\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in df8.columns if col != 'label']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "train = assembler.transform(train)\n",
        "test = assembler.transform(test)\n",
        "\n",
        "# Convert the train and test DataFrames to Pandas DataFrames\n",
        "train_pd = train.toPandas()\n",
        "test_pd = test.toPandas()\n",
        "\n",
        "# Create a TomekLinks object\n",
        "tl = TomekLinks()\n",
        "\n",
        "# Perform Tomek Links undersampling on the train and test data\n",
        "X_train_resampled, y_train_resampled = tl.fit_resample(train_pd[feature_cols], train_pd['label'])\n",
        "X_test_resampled, y_test_resampled = tl.fit_resample(test_pd[feature_cols], test_pd['label'])\n",
        "\n",
        "# Convert the resampled train and test data back to Spark DataFrames\n",
        "train_resampled_pd = pd.concat([pd.DataFrame(X_train_resampled, columns=feature_cols), pd.Series(y_train_resampled, name='label')], axis=1)\n",
        "train_resampled = spark.createDataFrame(train_resampled_pd)\n",
        "train_resampled = assembler.transform(train_resampled)\n",
        "\n",
        "test_resampled_pd = pd.concat([pd.DataFrame(X_test_resampled, columns=feature_cols), pd.Series(y_test_resampled, name='label')], axis=1)\n",
        "test_resampled = spark.createDataFrame(test_resampled_pd)\n",
        "test_resampled = assembler.transform(test_resampled)\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(seed=seed)\n",
        "\n",
        "# Fit the model to the resampled training data\n",
        "model = dt.fit(train_resampled)\n",
        "\n",
        "def calculate_metrics(predictions):\n",
        "    # Calculate ROC-AUC and accuracy metrics\n",
        "    evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "    roc_auc = evaluator_roc_auc.evaluate(predictions)\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "    metrics = MulticlassMetrics(predictionAndLabels)\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    # Manually calculate recall and F1 score\n",
        "    TP = confusion_matrix[1, 1]\n",
        "    FP = confusion_matrix[0, 1]\n",
        "    FN = confusion_matrix[1, 0]\n",
        "    precision_manual = TP / (TP + FP)\n",
        "    recall_manual = TP / (TP + FN)\n",
        "    f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "\n",
        "    return roc_auc, accuracy, precision_manual, recall_manual, f1_manual, confusion_matrix\n",
        "\n",
        "# Make predictions on the resampled training data and calculate metrics for training data\n",
        "predictions_train = model.transform(train_resampled)\n",
        "train_roc_auc, train_accuracy, train_precision, train_recall, train_f1Score, train_confusion_matrix = calculate_metrics(predictions_train)\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training ROC-AUC: {train_roc_auc:.3f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Training Precision: {train_precision:.3f}\")\n",
        "print(f\"Training Recall: {train_recall:.3f}\")\n",
        "print(f\"Training F1: {train_f1Score:.3f}\")\n",
        "print(f\"Training Confusion matrix:\\n{train_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the resampled test data and calculate metrics for test data\n",
        "predictions_test = model.transform(test_resampled)\n",
        "test_roc_auc, test_accuracy, test_precision, test_recall, test_f1Score, test_confusion_matrix = calculate_metrics(predictions_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Test Precision: {test_precision:.3f}\")\n",
        "print(f\"Test Recall: {test_recall:.3f}\")\n",
        "print(f\"Test F1: {test_f1Score:.3f}\")\n",
        "print(f\"Test Confusion matrix:\\n{test_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature matrix and label vector for df_oot2\n",
        "df_oot2 = assembler.transform(df_oot2)\n",
        "\n",
        "# Make predictions on the df_oot2 data and calculate metrics for df_oot2 data\n",
        "predictions_oot2 = model.transform(df_oot2)\n",
        "oot2_roc_auc, oot2_accuracy, oot2_precision, oot2_recall, oot2_f1Score, oot2_confusion_matrix = calculate_metrics(predictions_oot2)\n",
        "\n",
        "# Print df_oot2 metrics\n",
        "print(f\"df_oot2 ROC-AUC: {oot2_roc_auc:.3f}\")\n",
        "print(f\"df_oot2 Accuracy: {oot2_accuracy:.3f}\")\n",
        "print(f\"df_oot2 Precision: {oot2_precision:.3f}\")\n",
        "print(f\"df_oot2 Recall: {oot2_recall:.3f}\")\n",
        "print(f\"df_oot2 F1: {oot2_f1Score:.3f}\")\n",
        "print(f\"df_oot2 Confusion matrix:\\n{oot2_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature importances from the trained model\n",
        "importances = model.featureImportances\n",
        "\n",
        "# Create a dictionary of feature names and their importances\n",
        "importance_dict = dict(zip(feature_cols, importances))\n",
        "\n",
        "# Sort the dictionary by importance in descending order\n",
        "sorted_importance_dict = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the top 10 most important features and their importance values\n",
        "top_10_features = sorted_importance_dict[:10]\n",
        "\n",
        "# Print the top 10 most important features and their importance values\n",
        "print(\"Top 10 most important features:\")\n",
        "for feature, importance in top_10_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ],
      "metadata": {
        "id": "6ECRldgxFI-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#smote sin cross\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Rename the label column and cast it to DoubleType\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in df8.columns if col != 'label']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "train = assembler.transform(train)\n",
        "test = assembler.transform(test)\n",
        "\n",
        "# Convert the train and test DataFrames to Pandas DataFrames\n",
        "train_pd = train.toPandas()\n",
        "test_pd = test.toPandas()\n",
        "\n",
        "# Create a SMOTE object\n",
        "smote = SMOTE(random_state=seed)\n",
        "\n",
        "# Perform SMOTE oversampling on the train and test data\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(train_pd[feature_cols], train_pd['label'])\n",
        "X_test_resampled, y_test_resampled = smote.fit_resample(test_pd[feature_cols], test_pd['label'])\n",
        "\n",
        "# Convert the resampled train and test data back to Spark DataFrames\n",
        "train_resampled_pd = pd.concat([pd.DataFrame(X_train_resampled, columns=feature_cols), pd.Series(y_train_resampled, name='label')], axis=1)\n",
        "train_resampled = spark.createDataFrame(train_resampled_pd)\n",
        "train_resampled = assembler.transform(train_resampled)\n",
        "\n",
        "test_resampled_pd = pd.concat([pd.DataFrame(X_test_resampled, columns=feature_cols), pd.Series(y_test_resampled, name='label')], axis=1)\n",
        "test_resampled = spark.createDataFrame(test_resampled_pd)\n",
        "test_resampled = assembler.transform(test_resampled)\n",
        "\n",
        "# Train the GBT model without cross-validation\n",
        "gbt = GBTClassifier(seed=seed)\n",
        "\n",
        "# Fit the model to the resampled training data\n",
        "model = gbt.fit(train_resampled)\n",
        "\n",
        "def calculate_metrics(predictions):\n",
        "    # Calculate ROC-AUC and accuracy metrics\n",
        "    evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "    roc_auc = evaluator_roc_auc.evaluate(predictions)\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "    metrics = MulticlassMetrics(predictionAndLabels)\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    # Manually calculate recall and F1 score\n",
        "    TP = confusion_matrix[1, 1]\n",
        "    FP = confusion_matrix[0, 1]\n",
        "    FN = confusion_matrix[1, 0]\n",
        "    precision_manual = TP / (TP + FP)\n",
        "    recall_manual = TP / (TP + FN)\n",
        "    f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "\n",
        "    return roc_auc, accuracy, precision_manual, recall_manual, f1_manual, confusion_matrix\n",
        "\n",
        "# Make predictions on the resampled training data and calculate metrics for training data\n",
        "predictions_train = model.transform(train_resampled)\n",
        "train_roc_auc, train_accuracy, train_precision, train_recall, train_f1Score, train_confusion_matrix = calculate_metrics(predictions_train)\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training ROC-AUC: {train_roc_auc:.3f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Training Precision: {train_precision:.3f}\")\n",
        "print(f\"Training Recall: {train_recall:.3f}\")\n",
        "print(f\"Training F1: {train_f1Score:.3f}\")\n",
        "print(f\"Training Confusion matrix:\\n{train_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the resampled test data and calculate metrics for test data\n",
        "predictions_test = model.transform(test_resampled)\n",
        "test_roc_auc, test_accuracy, test_precision, test_recall, test_f1Score, test_confusion_matrix = calculate_metrics(predictions_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Test Precision: {test_precision:.3f}\")\n",
        "print(f\"Test Recall: {test_recall:.3f}\")\n",
        "print(f\"Test F1: {test_f1Score:.3f}\")\n",
        "print(f\"Test Confusion matrix:\\n{test_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature matrix and label vector for df_oot2\n",
        "df_oot2 = assembler.transform(df_oot2)\n",
        "\n",
        "# Make predictions on the df_oot2 data and calculate metrics for df_oot2 data\n",
        "predictions_oot2 = model.transform(df_oot2)\n",
        "oot2_roc_auc, oot2_accuracy, oot2_precision, oot2_recall, oot2_f1Score, oot2_confusion_matrix = calculate_metrics(predictions_oot2)\n",
        "\n",
        "# Print df_oot2 metrics\n",
        "print(f\"df_oot2 ROC-AUC: {oot2_roc_auc:.3f}\")\n",
        "print(f\"df_oot2 Accuracy: {oot2_accuracy:.3f}\")\n",
        "print(f\"df_oot2 Precision: {oot2_precision:.3f}\")\n",
        "print(f\"df_oot2 Recall: {oot2_recall:.3f}\")\n",
        "print(f\"df_oot2 F1: {oot2_f1Score:.3f}\")\n",
        "print(f\"df_oot2 Confusion matrix:\\n{oot2_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature importances from the trained model\n",
        "importances = model.featureImportances\n",
        "\n",
        "# Create a dictionary of feature names and their importances\n",
        "importance_dict = dict(zip(feature_cols, importances))\n",
        "\n",
        "# Sort the dictionary by importance in descending order\n",
        "sorted_importance_dict = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the top 10 most important features and their importance values\n",
        "top_10_features = sorted_importance_dict[:10]\n",
        "\n",
        "# Print the top 10 most important features and their importance values\n",
        "print(\"Top 10 most important features:\")\n",
        "for feature, importance in top_10_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ],
      "metadata": {
        "id": "YT6IYhUADtnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#smote con cross\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "# Rename the label column and cast it to DoubleType\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in df8.columns if col != 'label']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "train = assembler.transform(train)\n",
        "test = assembler.transform(test)\n",
        "\n",
        "# Convert the train and test DataFrames to Pandas DataFrames\n",
        "train_pd = train.toPandas()\n",
        "test_pd = test.toPandas()\n",
        "\n",
        "# Create a SMOTE object\n",
        "smote = SMOTE(random_state=seed)\n",
        "\n",
        "# Perform SMOTE oversampling on the train and test data\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(train_pd[feature_cols], train_pd['label'])\n",
        "X_test_resampled, y_test_resampled = smote.fit_resample(test_pd[feature_cols], test_pd['label'])\n",
        "\n",
        "# Convert the resampled train and test data back to Spark DataFrames\n",
        "train_resampled_pd = pd.concat([pd.DataFrame(X_train_resampled, columns=feature_cols), pd.Series(y_train_resampled, name='label')], axis=1)\n",
        "train_resampled = spark.createDataFrame(train_resampled_pd)\n",
        "train_resampled = assembler.transform(train_resampled)\n",
        "\n",
        "test_resampled_pd = pd.concat([pd.DataFrame(X_test_resampled, columns=feature_cols), pd.Series(y_test_resampled, name='label')], axis=1)\n",
        "test_resampled = spark.createDataFrame(test_resampled_pd)\n",
        "test_resampled = assembler.transform(test_resampled)\n",
        "\n",
        "# Train the GBT model with cross-validation\n",
        "gbt = GBTClassifier(seed=seed)\n",
        "\n",
        "# Create a parameter grid for hyperparameter tuning\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(gbt.maxDepth, [2, 5, 10]) \\\n",
        "    .addGrid(gbt.maxIter, [10, 20]) \\\n",
        "    .build()\n",
        "\n",
        "# Create a BinaryClassificationEvaluator object for evaluating the model during cross-validation\n",
        "evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create a CrossValidator object for performing cross-validation\n",
        "cv = CrossValidator(estimator=gbt,\n",
        "                    estimatorParamMaps=paramGrid,\n",
        "                    evaluator=evaluator_roc_auc,\n",
        "                    numFolds=5,\n",
        "                    seed=seed)\n",
        "\n",
        "# Fit the model to the resampled training data using cross-validation\n",
        "model = cv.fit(train_resampled)\n",
        "\n",
        "def calculate_metrics(predictions):\n",
        "    # Calculate ROC-AUC and accuracy metrics\n",
        "    evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "    roc_auc = evaluator_roc_auc.evaluate(predictions)\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "    metrics = MulticlassMetrics(predictionAndLabels)\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    # Manually calculate recall and F1 score\n",
        "    TP = confusion_matrix[1, 1]\n",
        "    FP = confusion_matrix[0, 1]\n",
        "    FN = confusion_matrix[1, 0]\n",
        "    precision_manual = TP / (TP + FP)\n",
        "    recall_manual = TP / (TP + FN)\n",
        "    f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "\n",
        "    return roc_auc, accuracy, precision_manual, recall_manual, f1_manual, confusion_matrix\n",
        "\n",
        "# Make predictions on the resampled training data and calculate metrics for training data\n",
        "predictions_train = model.transform(train_resampled)\n",
        "train_roc_auc, train_accuracy, train_precision, train_recall, train_f1Score, train_confusion_matrix = calculate_metrics(predictions_train)\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training ROC-AUC: {train_roc_auc:.3f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Training Precision: {train_precision:.3f}\")\n",
        "print(f\"Training Recall: {train_recall:.3f}\")\n",
        "print(f\"Training F1: {train_f1Score:.3f}\")\n",
        "print(f\"Training Confusion matrix:\\n{train_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the resampled test data and calculate metrics for test data\n",
        "predictions_test = model.transform(test_resampled)\n",
        "test_roc_auc, test_accuracy, test_precision, test_recall, test_f1Score, test_confusion_matrix = calculate_metrics(predictions_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Test Precision: {test_precision:.3f}\")\n",
        "print(f\"Test Recall: {test_recall:.3f}\")\n",
        "print(f\"Test F1: {test_f1Score:.3f}\")\n",
        "print(f\"Test Confusion matrix:\\n{test_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature matrix and label vector for df_oot2\n",
        "df_oot2 = assembler.transform(df_oot2)\n",
        "\n",
        "# Make predictions on the df_oot2 data and calculate metrics for df_oot2 data\n",
        "predictions_oot2 = model.transform(df_oot2)\n",
        "oot2_roc_auc, oot2_accuracy, oot2_precision, oot2_recall, oot2_f1Score, oot2_confusion_matrix = calculate_metrics(predictions_oot2)\n",
        "\n",
        "# Print df_oot2 metrics\n",
        "print(f\"df_oot2 ROC-AUC: {oot2_roc_auc:.3f}\")\n",
        "print(f\"df_oot2 Accuracy: {oot2_accuracy:.3f}\")\n",
        "print(f\"df_oot2 Precision: {oot2_precision:.3f}\")\n",
        "print(f\"df_oot2 Recall: {oot2_recall:.3f}\")\n",
        "print(f\"df_oot2 F1: {oot2_f1Score:.3f}\")\n",
        "print(f\"df_oot2 Confusion matrix:\\n{oot2_confusion_matrix}\")\n",
        "\n",
        "# Extract the feature importances from the trained model\n",
        "importances = model.bestModel.featureImportances\n",
        "\n",
        "# Create a dictionary of feature names and their importances\n",
        "importance_dict = dict(zip(feature_cols, importances))\n",
        "\n",
        "# Sort the dictionary by importance in descending order\n",
        "sorted_importance_dict = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the top 10 most important features and their importance values\n",
        "top_10_features = sorted_importance_dict[:10]\n",
        "\n",
        "# Print the top 10 most important features and their importance values\n",
        "print(\"Top 10 most important features:\")\n",
        "for feature, importance in top_10_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ],
      "metadata": {
        "id": "9T2FBGPUX2P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop = [column for column in df6.columns if any(corr_matrix_upper[np.where(df6.columns == column)[0]] >= 0.4) and column != 'Malo_Dias_tot']\n"
      ],
      "metadata": {
        "id": "ALf1PosEr7TB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}