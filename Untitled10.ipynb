{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNC6ljKxOg1v8bSl2zWi3Jp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristValen/Acciones-RNR/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "predictions_train = model.transform(train)\n",
        "\n",
        "# Calculate ROC-AUC and accuracy metrics for training data\n",
        "evaluator_train_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc_train = evaluator_train_roc_auc.evaluate(predictions_train)\n",
        "evaluator_train_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_train = evaluator_train_accuracy.evaluate(predictions_train)\n",
        "\n",
        "print(f\"Training ROC-AUC: {roc_auc_train:.3f}\")\n",
        "print(f\"Training Accuracy: {accuracy_train:.3f}\")\n",
        "\n",
        "# Calculate the confusion matrix for training data\n",
        "predictionAndLabels_train = predictions_train.select(\"prediction\", \"label\").rdd\n",
        "metrics_train = MulticlassMetrics(predictionAndLabels_train)\n",
        "confusion_matrix_train = metrics_train.confusionMatrix().toArray()\n",
        "print(f\"Training Confusion matrix:\\n{confusion_matrix_train}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for training data\n",
        "TP_train = confusion_matrix_train[1, 1]\n",
        "FP_train = confusion_matrix_train[0, 1]\n",
        "FN_train = confusion_matrix_train[1, 0]\n",
        "precision_manual_train = TP_train / (TP_train + FP_train)\n",
        "recall_manual_train = TP_train / (TP_train + FN_train)\n",
        "f1_manual_train = 2 * (precision_manual_train * recall_manual_train) / (precision_manual_train + recall_manual_train)\n",
        "print(f\"Training Recall (manually calculated): {recall_manual_train:.3f}\")\n",
        "print(f\"Training F1 (manually calculated): {f1_manual_train:.3f}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Define a user-defined function to extract the probability of class 1\n",
        "extract_probability = udf(lambda v: float(v[1]), DoubleType())\n",
        "\n",
        "# Create a new column with the probability of class 1 in the predictions DataFrame\n",
        "predictions_train = predictions_train.withColumn('score', extract_probability('probability'))\n",
        "\n",
        "# Calculate the KS statistic for the training data\n",
        "ks_value = calc_ks(predictions_train)\n",
        "print(f\"Training KS: {ks_value:.3f}\")\n"
      ],
      "metadata": {
        "id": "dFZABeDLL0ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf, when, percent_rank\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "predictions_train = model.transform(train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions_test = model.transform(test)\n",
        "\n",
        "# Create a UDF to extract the score from the probability column\n",
        "def extract_score(vector):\n",
        "    return float(vector[1])\n",
        "\n",
        "extract_score_udf = udf(extract_score, DoubleType())\n",
        "\n",
        "# Create the score column in the predictions DataFrames\n",
        "predictions_train = predictions_train.withColumn('score', extract_score_udf('probability'))\n",
        "predictions_test = predictions_test.withColumn('score', extract_score_udf('probability'))\n",
        "\n",
        "# Convert the predictions to an RDD and calculate metrics using MulticlassMetrics\n",
        "predictionAndLabels_train = predictions_train.select(\"prediction\", \"label\").rdd\n",
        "metrics_train = MulticlassMetrics(predictionAndLabels_train)\n",
        "confusion_matrix_train = metrics_train.confusionMatrix().toArray()\n",
        "print(f\"Training Confusion matrix:\\n{confusion_matrix_train}\")\n",
        "\n",
        "predictionAndLabels_test = predictions_test.select(\"prediction\", \"label\").rdd\n",
        "metrics_test = MulticlassMetrics(predictionAndLabels_test)\n",
        "confusion_matrix_test = metrics_test.confusionMatrix().toArray()\n",
        "print(f\"Test Confusion matrix:\\n{confusion_matrix_test}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for training data\n",
        "TP_train = confusion_matrix_train[1, 1]\n",
        "FP_train = confusion_matrix_train[0, 1]\n",
        "FN_train = confusion_matrix_train[1, 0]\n",
        "\n",
        "precision_train = TP_train / (TP_train + FP_train)\n",
        "recall_train = TP_train / (TP_train + FN_train)\n",
        "f1_score_train = 2 * (precision_train * recall_train) / (precision_train + recall_train)\n",
        "\n",
        "print(f\"Training Precision: {precision_train}\")\n",
        "print(f\"Training Recall: {recall_train}\")\n",
        "print(f\"Training F1 Score: {f1_score_train}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for test data\n",
        "TP_test = confusion_matrix_test[1, 1]\n",
        "FP_test = confusion_matrix_test[0, 1]\n",
        "FN_test = confusion_matrix_test[1, 0]\n",
        "\n",
        "precision_test = TP_test / (TP_test + FP_test)\n",
        "recall_test = TP_test / (TP_test + FN_test)\n",
        "f1_score_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n",
        "\n",
        "print(f\"Test Precision: {precision_test}\")\n",
        "print(f\"Test Recall: {recall_test}\")\n",
        "print(f\"Test F1 Score: {f1_score_test}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.withColumn('good', when(col('label') == 0, 1).otherwise(0)) \\\n",
        "                .withColumn('bad', when(col('label') == 1, 1).otherwise(0)) \\\n",
        "                .withColumn('bucket', (percent_rank().over(Window.orderBy('score'))*10).cast(IntegerType()))\n",
        "    grouped=data_pd.groupBy('bucket')\n",
        "    kstable=grouped.agg(min(col('score')).alias('min_score'), max(col('score')).alias('max_score'), sum(col('bad')).alias('bads'), sum(col('good')).alias('goods'))\n",
        "    kstable=kstable.withColumn('bad_rate', col('bads')/(col('bads')+col('goods')))\n",
        "    kstable=kstable.withColumn('ks', (sum(col('bads')).over(Window.orderBy('bucket'))/kstable.select(sum(col('bads'))).collect()[0][0])-(sum(col('goods')).over(Window.orderBy('bucket'))/kstable.select(sum(col('goods'))).collect()[0][0]))\n",
        "    ks_value=kstable.select(max(abs(col('ks')))).collect()[0][0]\n",
        "    return ks_value\n",
        "\n",
        "ks_value_train=calc_ks(predictions_train)\n",
        "ks_value_test=calc_ks(predictions_test)\n",
        "\n",
        "print(f\"Training KS: {ks_value_train}\")\n",
        "print(f\"Test KS: {ks_value_test}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "f9YfrL0s59ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from pyspark.sql import Row\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Set the seed for the random number generator\n",
        "random_state = 0\n",
        "\n",
        "# Convert the Spark DataFrame to a Pandas DataFrame\n",
        "data_pd = df_2.toPandas()\n",
        "\n",
        "# Define the feature columns\n",
        "feature_cols = [col for col in data_pd.columns if col != 'Malo_Dias_tot']\n",
        "\n",
        "# Extract the feature matrix and label vector\n",
        "X = data_pd[feature_cols].values\n",
        "y = data_pd['Malo_Dias_tot'].values\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Create a SMOTE object\n",
        "smote = SMOTE(random_state=random_state)\n",
        "\n",
        "# Train the Decision Tree model without cross-validation\n",
        "dt = DecisionTreeClassifier(random_state=random_state)\n",
        "\n",
        "# Create a pipeline to chain SMOTE and Decision Tree together\n",
        "pipeline = Pipeline([('smote', smote), ('dt', dt)])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Perform SMOTE oversampling on the test data\n",
        "X_test_resampled, y_test_resampled = smote.fit_resample(X_test, y_test)\n",
        "\n",
        "# Predict values for the oversampled test set\n",
        "y_pred = model.predict(X_train_resampled)\n",
        "\n",
        "# Calculate metrics\n",
        "tn, fp, fn, tp = confusion_matrix(y_train_resampled, y_pred).ravel()\n",
        "\n",
        "print(f'Confusion Matrix:\\n[[{tn} {fp}]\\n [{fn} {tp}]]')\n",
        "\n",
        "accuracy = accuracy_score(y_train_resampled, y_pred)\n",
        "precision = precision_score(y_train_resampled, y_pred)\n",
        "recall = recall_score(y_train_resampled, y_pred)\n",
        "f1_score = f1_score(y_train_resampled, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1_score}')\n",
        "\n",
        "# Convert the true labels and predicted scores to int data type\n",
        "y_train_resampled = y_train_resampled.astype(int)\n",
        "y_pred = y_pred.astype(int)\n",
        "\n",
        "# Create a list of Row objects containing the true labels and predicted scores\n",
        "rows = [Row(label=int(label), score=int(score)) for label, score in zip(y_train_resampled, y_pred)]\n",
        "\n",
        "# Convert the list of Row objects to a PySpark DataFrame\n",
        "predictions_train = spark.createDataFrame(rows)\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.withColumn('good', when(col('label') == 0, 1).otherwise(0)) \\\n",
        "                .withColumn('bad', when(col('label') == 1, 1).otherwise(0)) \\\n",
        "                .withColumn('bucket', (percent_rank().over(Window.orderBy('score'))*10).cast(IntegerType()))\n",
        "    grouped=data_pd.groupBy('bucket')\n",
        "    kstable=grouped.agg(min(col('score')).alias('min_score'), max(col('score')).alias('max_score'), sum(col('bad')).alias('bads'), sum(col('good')).alias('goods'))\n",
        "    kstable=kstable.withColumn('bad_rate', col('bads')/(col('bads')+col('goods')))\n",
        "    kstable=kstable.withColumn('ks', (sum(col('bads')).over(Window.orderBy('bucket'))/kstable.select(sum(col('bads'))).collect()[0][0])-(sum(col('goods')).over(Window.orderBy('bucket'))/kstable.select(sum(col('goods'))).collect()[0][0]))\n",
        "    ks_value=kstable.select(max(abs(col('ks')))).collect()[0][0]\n",
        "    return ks_value\n",
        "\n",
        "ks_value_train=calc_ks(predictions_train)\n",
        "\n",
        "print(f\"Training KS: {ks_value_train}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nscpUVuClnLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### con funcion\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = cv.fit(train)\n",
        "\n",
        "def calculate_metrics(predictions):\n",
        "    # Calculate ROC-AUC and accuracy metrics\n",
        "    evaluator_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "    roc_auc = evaluator_roc_auc.evaluate(predictions)\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    predictionAndLabels = predictions.select(\"prediction\", \"label\").rdd\n",
        "    metrics = MulticlassMetrics(predictionAndLabels)\n",
        "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
        "\n",
        "    # Manually calculate recall and F1 score\n",
        "    TP = confusion_matrix[1, 1]\n",
        "    FP = confusion_matrix[0, 1]\n",
        "    FN = confusion_matrix[1, 0]\n",
        "    precision_manual = TP / (TP + FP)\n",
        "    recall_manual = TP / (TP + FN)\n",
        "    f1_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual)\n",
        "\n",
        "    return roc_auc, accuracy, precision_manual, recall_manual, f1_manual, confusion_matrix\n",
        "\n",
        "# Make predictions on the training data and calculate metrics for training data\n",
        "predictions_train = model.transform(train)\n",
        "train_roc_auc, train_accuracy, train_precision, train_recall, train_f1Score, train_confusion_matrix = calculate_metrics(predictions_train)\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training ROC-AUC: {train_roc_auc:.3f}\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
        "print(f\"Training Precision: {train_precision:.3f}\")\n",
        "print(f\"Training Recall: {train_recall:.3f}\")\n",
        "print(f\"Training F1: {train_f1Score:.3f}\")\n",
        "print(f\"Training Confusion matrix:\\n{train_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the test data and calculate metrics for test data\n",
        "predictions_test = model.transform(test)\n",
        "test_roc_auc, test_accuracy, test_precision, test_recall, test_f1Score, test_confusion_matrix = calculate_metrics(predictions_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Test Precision: {test_precision:.3f}\")\n",
        "print(f\"Test Recall: {test_recall:.3f}\")\n",
        "print(f\"Test F1: {test_f1Score:.3f}\")\n",
        "print(f\"Test Confusion matrix:\\n{test_confusion_matrix}\")\n",
        "\n",
        "# Make predictions on the df_oot data and calculate metrics for df_oot data\n",
        "predictions_oot = model.transform(df_oot)\n",
        "oot_roc_auc, oot_accuracy, oot_precision, oot_recall, oot_f1Score, oot_confusion_matrix = calculate_metrics(predictions_oot)\n",
        "\n",
        "# Print df_oot metrics\n",
        "print(f\"df_oot ROC-AUC: {oot_roc_auc:.3f}\")\n",
        "print(f\"df_oot Accuracy: {oot_accuracy:.3f}\")\n",
        "print(f\"df_oot Precision: {oot_precision:.3f}\")\n",
        "print(f\"df_oot Recall: {oot_recall:.3f}\")\n",
        "print(f\"df_oot F1: {oot_f1Score:.3f}\")\n",
        "print(f\"df_oot Confusion matrix:\\n{oot_confusion_matrix}\")\n"
      ],
      "metadata": {
        "id": "1LnrmAvvodnu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}