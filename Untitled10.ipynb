{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIZoEJUxYbatOEKo0pfI7b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristValen/Acciones-RNR/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA7MCKZGE1EO"
      },
      "outputs": [],
      "source": [
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "model = cv.fit(train)\n",
        "\n",
        "predictions_train = model.transform(train)\n",
        "\n",
        "evaluator_train_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc_train = evaluator_train_roc_auc.evaluate(predictions_train)\n",
        "evaluator_train_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_train = evaluator_train_accuracy.evaluate(predictions_train)\n",
        "\n",
        "print(f\"Training ROC-AUC: {roc_auc_train:.3f}\")\n",
        "print(f\"Training Accuracy: {accuracy_train:.3f}\")\n",
        "\n",
        "# Calculate the confusion matrix for training data\n",
        "predictionAndLabels_train = predictions_train.select(\"prediction\", \"label\").rdd\n",
        "metrics_train = MulticlassMetrics(predictionAndLabels_train)\n",
        "confusion_matrix_train = metrics_train.confusionMatrix().toArray()\n",
        "print(f\"Training Confusion matrix:\\n{confusion_matrix_train}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for training data\n",
        "TP_train = confusion_matrix_train[1, 1]\n",
        "FP_train = confusion_matrix_train[0, 1]\n",
        "FN_train = confusion_matrix_train[1, 0]\n",
        "precision_manual_train = TP_train / (TP_train + FP_train)\n",
        "recall_manual_train = TP_train / (TP_train + FN_train)\n",
        "f1_manual_train = 2 * (precision_manual_\\<EUGPSCoordinates\\>train * recall_manual_\\<EUGPSCoordinates\\>train) / (precision_manual_\\<EUGPSCoordinates\\>train + recall_manual_\\<EUGPSCoordinates\\>train)\n",
        "print(f\"Training Recall (manually calculated): {recall_manual_\\<EUGPSCoordinates\\>train:.3f}\")\n",
        "print(f\"Training F1 (manually calculated): {f1_manual_\\<EUGPSCoordinates\\>train:.3f}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd = data.toPandas()\n",
        "    data_pd['good'] = (data_pd['label'] == 0).astype(int)\n",
        "    data_pd['bad'] = (data_pd['label'] == 1).astype(int)\n",
        "    data_pd['bucket'] = (data_pd['score'].rank(pct=True) * 10).astype(int)\n",
        "    grouped = data_pd.groupby('bucket', as_index=True)\n",
        "    kstable = grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score'] = grouped.max().score\n",
        "    kstable['bads'] = grouped.sum().bad\n",
        "    kstable['goods'] = grouped.sum().good\n",
        "    kstable.reset_index(inplace=True)\n",
        "    kstable['bad_rate'] = kstable.bads / (kstable.bads + kstable.goods)\n",
        "    kstable['ks'] = (kstable.bads / kstable.bads.sum()).cumsum() - \\\n",
        "                    (kstable.goods / kstable.goods.sum()).cumsum()\n",
        "    ks_value = kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Calculate the KS statistic for the training data\n",
        "score_udf = udf(lambda v: float(v[1]), DoubleType())\n",
        "predictions_train = predictions_train.withColumn('score', score_udf('probability'))\n",
        "ks_value_train = calc_ks(predictions_train)\n",
        "print(f\"Training KS: {ks_value_train:.3f}\")\n",
        "\n",
        "# Get the most important features\n",
        "importances = model.bestModel.stages[-1].featureImportances\n",
        "important_features = sorted(zip(importances, features), reverse=True)\n",
        "print(\"Most important features:\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ]
    }
  ]
}