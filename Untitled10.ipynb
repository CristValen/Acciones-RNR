{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNUDM+NpFa4Wlbk60Uno4H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristValen/Acciones-RNR/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "predictions_train = model.transform(train)\n",
        "\n",
        "# Calculate ROC-AUC and accuracy metrics for training data\n",
        "evaluator_train_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc_train = evaluator_train_roc_auc.evaluate(predictions_train)\n",
        "evaluator_train_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_train = evaluator_train_accuracy.evaluate(predictions_train)\n",
        "\n",
        "print(f\"Training ROC-AUC: {roc_auc_train:.3f}\")\n",
        "print(f\"Training Accuracy: {accuracy_train:.3f}\")\n",
        "\n",
        "# Calculate the confusion matrix for training data\n",
        "predictionAndLabels_train = predictions_train.select(\"prediction\", \"label\").rdd\n",
        "metrics_train = MulticlassMetrics(predictionAndLabels_train)\n",
        "confusion_matrix_train = metrics_train.confusionMatrix().toArray()\n",
        "print(f\"Training Confusion matrix:\\n{confusion_matrix_train}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for training data\n",
        "TP_train = confusion_matrix_train[1, 1]\n",
        "FP_train = confusion_matrix_train[0, 1]\n",
        "FN_train = confusion_matrix_train[1, 0]\n",
        "precision_manual_train = TP_train / (TP_train + FP_train)\n",
        "recall_manual_train = TP_train / (TP_train + FN_train)\n",
        "f1_manual_train = 2 * (precision_manual_train * recall_manual_train) / (precision_manual_train + recall_manual_train)\n",
        "print(f\"Training Recall (manually calculated): {recall_manual_train:.3f}\")\n",
        "print(f\"Training F1 (manually calculated): {f1_manual_train:.3f}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.toPandas()\n",
        "    data_pd['good']=(data_pd['label']==0).astype(int)\n",
        "    data_pd['bad']=(data_pd['label']==1).astype(int)\n",
        "    data_pd['bucket']=(data_pd['score'].rank(pct=True)*10).astype(int)\n",
        "    grouped=data_pd.groupby('bucket',as_index=True)\n",
        "    kstable=grouped.min().score.to_frame(name='min_score')\n",
        "    kstable['max_score']=grouped.max().score\n",
        "    kstable['bads']=grouped.sum().bad\n",
        "    kstable['goods']=grouped.sum().good\n",
        "    kstable=kstable.reset_index()\n",
        "    kstable['bad_rate']=kstable.bads/(kstable.bads+kstable.goods)\n",
        "    kstable['ks']=(kstable.bads/kstable.bads.sum()).cumsum()-(kstable.goods/kstable.goods.sum()).cumsum()\n",
        "    ks_value=kstable.ks.abs().max()\n",
        "    return ks_value\n",
        "\n",
        "# Define a user-defined function to extract the probability of class 1\n",
        "extract_probability = udf(lambda v: float(v[1]), DoubleType())\n",
        "\n",
        "# Create a new column with the probability of class 1 in the predictions DataFrame\n",
        "predictions_train = predictions_train.withColumn('score', extract_probability('probability'))\n",
        "\n",
        "# Calculate the KS statistic for the training data\n",
        "ks_value = calc_ks(predictions_train)\n",
        "print(f\"Training KS: {ks_value:.3f}\")\n"
      ],
      "metadata": {
        "id": "dFZABeDLL0ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics\n",
        "from pyspark.sql.functions import col, udf, when, percent_rank\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = cv.fit(train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "predictions_train = model.transform(train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions_test = model.transform(test)\n",
        "\n",
        "# Create a UDF to extract the score from the probability column\n",
        "def extract_score(vector):\n",
        "    return float(vector[1])\n",
        "\n",
        "extract_score_udf = udf(extract_score, DoubleType())\n",
        "\n",
        "# Create the score column in the predictions DataFrames\n",
        "predictions_train = predictions_train.withColumn('score', extract_score_udf('probability'))\n",
        "predictions_test = predictions_test.withColumn('score', extract_score_udf('probability'))\n",
        "\n",
        "# Convert the predictions to an RDD and calculate metrics using MulticlassMetrics\n",
        "predictionAndLabels_train = predictions_train.select(\"prediction\", \"label\").rdd\n",
        "metrics_train = MulticlassMetrics(predictionAndLabels_train)\n",
        "confusion_matrix_train = metrics_train.confusionMatrix().toArray()\n",
        "print(f\"Training Confusion matrix:\\n{confusion_matrix_train}\")\n",
        "\n",
        "predictionAndLabels_test = predictions_test.select(\"prediction\", \"label\").rdd\n",
        "metrics_test = MulticlassMetrics(predictionAndLabels_test)\n",
        "confusion_matrix_test = metrics_test.confusionMatrix().toArray()\n",
        "print(f\"Test Confusion matrix:\\n{confusion_matrix_test}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for training data\n",
        "TP_train = confusion_matrix_train[1, 1]\n",
        "FP_train = confusion_matrix_train[0, 1]\n",
        "FN_train = confusion_matrix_train[1, 0]\n",
        "\n",
        "precision_train = TP_train / (TP_train + FP_train)\n",
        "recall_train = TP_train / (TP_train + FN_train)\n",
        "f1_score_train = 2 * (precision_train * recall_train) / (precision_train + recall_train)\n",
        "\n",
        "print(f\"Training Precision: {precision_train}\")\n",
        "print(f\"Training Recall: {recall_train}\")\n",
        "print(f\"Training F1 Score: {f1_score_train}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for test data\n",
        "TP_test = confusion_matrix_test[1, 1]\n",
        "FP_test = confusion_matrix_test[0, 1]\n",
        "FN_test = confusion_matrix_test[1, 0]\n",
        "\n",
        "precision_test = TP_test / (TP_test + FP_test)\n",
        "recall_test = TP_test / (TP_test + FN_test)\n",
        "f1_score_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n",
        "\n",
        "print(f\"Test Precision: {precision_test}\")\n",
        "print(f\"Test Recall: {recall_test}\")\n",
        "print(f\"Test F1 Score: {f1_score_test}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.withColumn('good', when(col('label') == 0, 1).otherwise(0)) \\\n",
        "                .withColumn('bad', when(col('label') == 1, 1).otherwise(0)) \\\n",
        "                .withColumn('bucket', (percent_rank().over(Window.orderBy('score'))*10).cast(IntegerType()))\n",
        "    grouped=data_pd.groupBy('bucket')\n",
        "    kstable=grouped.agg(min(col('score')).alias('min_score'), max(col('score')).alias('max_score'), sum(col('bad')).alias('bads'), sum(col('good')).alias('goods'))\n",
        "    kstable=kstable.withColumn('bad_rate', col('bads')/(col('bads')+col('goods')))\n",
        "    kstable=kstable.withColumn('ks', (sum(col('bads')).over(Window.orderBy('bucket'))/kstable.select(sum(col('bads'))).collect()[0][0])-(sum(col('goods')).over(Window.orderBy('bucket'))/kstable.select(sum(col('goods'))).collect()[0][0]))\n",
        "    ks_value=kstable.select(max(abs(col('ks')))).collect()[0][0]\n",
        "    return ks_value\n",
        "\n",
        "ks_value_train=calc_ks(predictions_train)\n",
        "ks_value_test=calc_ks(predictions_test)\n",
        "\n",
        "print(f\"Training KS: {ks_value_train}\")\n",
        "print(f\"Test KS: {ks_value_test}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "f9YfrL0s59ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from imblearn.under_sampling import NearMiss\n",
        "import pandas as pd\n",
        "\n",
        "df8 = df_2.withColumnRenamed('Malo_Dias_tot', 'label')\n",
        "df8 = df8.withColumn(\"label\", col(\"label\").cast(DoubleType()))\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 12345\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train, test = df8.randomSplit([0.7, 0.3], seed=seed)\n",
        "\n",
        "# Convert the training data to a Pandas DataFrame\n",
        "train_pd = train.toPandas()\n",
        "\n",
        "# Define features and label\n",
        "features = df8.columns\n",
        "features.remove('label')\n",
        "\n",
        "# Separate the features and label\n",
        "X = train_pd[features]\n",
        "y = train_pd['label']\n",
        "\n",
        "# Perform NearMiss undersampling\n",
        "nm = NearMiss()\n",
        "X_resampled, y_resampled = nm.fit_resample(X, y)\n",
        "\n",
        "# Convert the resampled data back to a PySpark DataFrame\n",
        "train_undersampled_pd = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "train_undersampled = spark.createDataFrame(train_undersampled_pd)\n",
        "\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "\n",
        "# Create the Random Forest model\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=seed)\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "# Define the parameter grid for cross-validation\n",
        "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [10, 20]).build()\n",
        "\n",
        "# Define the evaluator for cross-validation\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Create the cross-validator object\n",
        "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator)\n",
        "\n",
        "# Fit the model on the undersampled training data\n",
        "model = cv.fit(train_undersampled)\n",
        "\n",
        "# Make predictions on the original training data\n",
        "predictions_train_original = model.transform(train)\n",
        "\n",
        "# Calculate ROC-AUC and accuracy metrics for original training data\n",
        "evaluator_train_original_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc_train_original = evaluator_train_original_roc_auc.evaluate(predictions_train_original)\n",
        "evaluator_train_original_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_train_original = evaluator_train_original_accuracy.evaluate(predictions_train_original)\n",
        "\n",
        "print(f\"Training (original) ROC-AUC: {roc_auc_train_original:.3f}\")\n",
        "print(f\"Training (original) Accuracy: {accuracy_train_original:.3f}\")\n",
        "\n",
        "# Calculate the confusion matrix for original training data\n",
        "predictionAndLabels_train_original = predictions_train_original.select(\"prediction\", \"label\").rdd\n",
        "metrics_train_original = MulticlassMetrics(predictionAndLabels_train_original)\n",
        "confusion_matrix_train_original = metrics_train_original.confusionMatrix().toArray()\n",
        "print(f\"Training (original) Confusion matrix:\\n{confusion_matrix_train_original}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for original training data\n",
        "TP_train_original = confusion_matrix_train_original[1, 1]\n",
        "FP_train_original = confusion_matrix_train_original[0, 1]\n",
        "FN_train_original = confusion_matrix_train_original[1, 0]\n",
        "precision_manual_train_original = TP_train_original / (TP_train_original + FP_train_original)\n",
        "recall_manual_train_original = TP_train_original / (TP_train_original + FN_train_original)\n",
        "f1_manual_train_original = 2 * (precision_manual_train_original * recall_manual_train_original) / (precision_manual_train_original + recall_manual_train_original)\n",
        "print(f\"Training (original) Recall (manually calculated): {recall_manual_train_original:.3f}\")\n",
        "print(f\"Training (original) F1 (manually calculated): {f1_manual_train_original:.3f}\")\n",
        "\n",
        "def calc_ks(data):\n",
        "    data_pd=data.withColumn('good', when(col('label') == 0, 1).otherwise(0)) \\\n",
        "                .withColumn('bad', when(col('label') == 1, 1).otherwise(0)) \\\n",
        "                .withColumn('bucket', (percent_rank().over(Window.orderBy('score'))*10).cast(IntegerType()))\n",
        "    grouped=data_pd.groupBy('bucket')\n",
        "    kstable=grouped.agg(min(col('score')).alias('min_score'), max(col('score')).alias('max_score'), sum(col('bad')).alias('bads'), sum(col('good')).alias('goods'))\n",
        "    kstable=kstable.withColumn('bad_rate', col('bads')/(col('bads')+col('goods')))\n",
        "    kstable=kstable.withColumn('ks', (sum(col('bads')).over(Window.orderBy('bucket'))/kstable.select(sum(col('bads'))).collect()[0][0])-(sum(col('goods')).over(Window.orderBy('bucket'))/kstable.select(sum(col('goods'))).collect()[0][0]))\n",
        "    ks_value=kstable.select(max(abs(col('ks')))).collect()[0][0]\n",
        "    return ks_value\n",
        "\n",
        "ks_value_train_original=calc_ks(predictions_train_original)\n",
        "print(f\"Training (original) KS: {ks_value_train_original:.3f}\")\n",
        "\n",
        "# Convert the test data to a Pandas DataFrame\n",
        "test_pd = test.toPandas()\n",
        "\n",
        "# Separate the features and label in the test data\n",
        "X_test = test_pd[features]\n",
        "y_test = test_pd['label']\n",
        "\n",
        "# Perform NearMiss undersampling on the test data\n",
        "X_test_resampled, y_test_resampled = nm.fit_resample(X_test, y_test)\n",
        "\n",
        "# Convert the resampled test data back to a PySpark DataFrame\n",
        "test_undersampled_pd = pd.concat([X_test_resampled, y_test_resampled], axis=1)\n",
        "test_undersampled = spark.createDataFrame(test_undersampled_pd)\n",
        "\n",
        "# Make predictions on the undersampled test data\n",
        "predictions_test = model.transform(test_undersampled)\n",
        "\n",
        "# Calculate ROC-AUC and accuracy metrics for test data\n",
        "evaluator_test_roc_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "roc_auc_test = evaluator_test_roc_auc.evaluate(predictions_test)\n",
        "evaluator_test_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy_test = evaluator_test_accuracy.evaluate(predictions_test)\n",
        "\n",
        "print(f\"Test ROC-AUC: {roc_auc_test:.3f}\")\n",
        "print(f\"Test Accuracy: {accuracy_test:.3f}\")\n",
        "\n",
        "# Calculate the confusion matrix for test data\n",
        "predictionAndLabels_test = predictions_test.select(\"prediction\", \"label\").rdd\n",
        "metrics_test = MulticlassMetrics(predictionAndLabels_test)\n",
        "confusion_matrix_test = metrics_test.confusionMatrix().toArray()\n",
        "print(f\"Test Confusion matrix:\\n{confusion_matrix_test}\")\n",
        "\n",
        "# Manually calculate recall and F1 score for test data\n",
        "TP_test = confusion_matrix_test[1, 1]\n",
        "FP_test = confusion_matrix_test[0, 1]\n",
        "FN_test = confusion_matrix_test[1, 0]\n",
        "precision_manual_test = TP_train / (TP_train + FP_train)\n",
        "recall_manual_train = TP_train / (TP_train + FN_train)\n",
        "f1_manual_train = 2 * (precision_manual_train * recall_manual_train) / (precision_manual_train + recall_manual_train)\n",
        "print(f\"Test Recall (manually calculated): {recall_manual_train:.3f}\")\n",
        "print(f\"Test F1 (manually calculated): {f1_manual_train:.3f}\")\n",
        "\n",
        "ks_value_test=calc_ks(predictions_test)\n",
        "print(f\"Test KS: {ks_value_train:.3f}\")\n",
        "\n",
        "# Get the most important features\n",
        "importances = model.bestModel.stages[-1].featureImportances\n",
        "important_features = sorted(zip(importances, features), reverse=True)\n",
        "print(\"Most important features:\")\n",
        "for importance, feature in important_features:\n",
        "    print(f\"{feature}: {importance:.3f}\")\n"
      ],
      "metadata": {
        "id": "nscpUVuClnLY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}